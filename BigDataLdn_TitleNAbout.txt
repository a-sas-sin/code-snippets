Big Data LDN 2023 – Chairman’s Opening Address & Welcome
Mike Ferguson, Conference Chair, will discuss the hottest trends in Data that have emerged over the last year and outline the key themes for Big Data LDN 2023
Setting the Foundations of Your Data Strategy to Maximise the Power of AI/ML
-How do you enable seamless collaboration and maximize productivity between ML practitioners and end users-within your own organization and beyond?
-How do you avoid fractured data stacks and governance to accelerate successful AI deployments? -How do you easily scale your data stack to the demands of AI/ML?
Successful adoption of AI/ML are increasingly essential for competitive success. In order to deliver on the promise of these technologies, there are foundational elements of your data strategy that need to be considered:
-How do you discover, collect, curate, and access the best data sets for optimal business outcomes in AI/ML?
In this executive-level session, we will delve into industry trends and challenges, and explore how the right Data Cloud strategy can accelerate and scale your AI/ML adoption.
Maximizing the Value of Your Data Assets
We live in a data-driven world and we are surrounded by vast amounts of data, yet 90% of it is underutilized. The definition of insanity is doing the same thing (creating data silos) over and over again and expecting a different outcome. Yet this is exactly what we are doing today. This session will showcase how organizations can dramatically improve time to information insight, and reduce TCO while providing massive scalability and performance by decentralizing (vs. centralizing) information access. The outcome of this approach is a set of reusable assets known as Data Products, which become the key to unlocking the value, speed, and efficiency of your future analytical endeavors.This is particularly vital for crucial topics like GenAI and the LLM that power them. In a world where data is king, enabling access to decentralized data assets is critical to accelerating innovation in any organization.
Building Data Products on Snowflake using DataOps
Data Products are all the rage. But to have real impact, it is essential to use the right methodology and tools to build and manage them. By bringing the best aspects of DevOps to Data, DataOps is that methodology. And when deployed using a leading platform like DataOps.live, you can achieve unmatched developer productivity without compromising on agility and governance. Join Guy Adams, CTO, DataOps.live (and Snowflake Data Superhero), Thomas Steinborn, SVP of Products, DataOps.live and Miguel Morgado, SPO of Digital Products, OneWeb, as they lead you through the journey from automated development, orchestration, observability and deployment to effective lifecycle management of Data Products - all with clear optics on how the business stakeholders can benefit from this breakthrough approach.
Thomas Steinborn, SVP of Products, comes to DataOps.live with over 20 years of experience in integration technology ranging from application integration over data integration to data governance. He believes in DevSecOps principles as applied to Data Products and Data Operations (DataOps) and has brought them to the products he's led since 2005. Thomas has spent over ten years scaling product management organizations at the global level. Before DataOps, he was Chief Product Officer at Infoniqa, the Human Capital Management, Payroll, and Time Solutions leader in the DACH region. Before that, he led product and user experience as VP of Products at Talend, a leading provider of data integration, data integrity, and data governance solutions.
Guy Adams is CTO and co-founder at DataOps.live. He is a passionate advocate of #TrueDataOps and the #1 Snowflake Data Superhero globally. He was a founder of the #TrueDataops Philosophy (www.truedataops.org) and author of DataOps for Dummies and Data Products for Dummies books.
Miguel Morgado, SPO Digital Products, OneWeb, is a Product Owner with a focus on Cloud Data Analytics and Management.  OneWeb is an innovative communications company building a truly global communications network in space that will deliver low latency, high-speed internet services that connect people everywhere. Miguel has 20+ years of experience designing and delivering solutions for teams to collaborate and communicate around data and gain unmatched insights to drive innovation.  Miguel's team supports a global organization charged with helping to understand and optimize the operational complexities of OneWeb's network.
Speaker bios:
You’re Building a Data Culture… How Are Those Sleepless Nights?
Join LVMH Data Governance Lead Baudouin du Baret and DataGalaxy Chief Evangelist Laurent Dresse for the keynote speech 'You're Building a Data Culture' How are Those Sleepless Nights?'
Additionally, Laurent and Baudouin will outline challenges often faced by data leaders and their teams as they navigate the complexities of data-driven decision-making, data governance, and organizational data integration. The keynote will also highlight the importance of fostering a data-driven culture and mindset across all levels of an organization, and the transformative impact data governance can have on business outcomes.
In this talk, Baudouin will present how LVMH has launched its data transformation journey while overcoming major challenges along the way. He will share key takeaways and best practices, and showcase how a data catalog enables the world's largest luxury goods company to achieve its data management and governance goals.
Scaling data quality with unsupervised machine learning methods
Companies are utilizing rules and metrics to monitor data quality, but they're tedious to set up and maintain. Vicky will present a set of fully unsupervised machine learning algorithms for monitoring data quality at scale. Which require no set up, catch unexpected issues and prevent alert fatigue by minimizing false positives. At the end of this session, participants will be equipped with insight into unsupervised data quality monitoring, its advantages and limitations, and how it can help scale trust in your data.
The perfect couple: Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
Large Language models are amazing but are also black-box models that often fail to capture and accurately represent factual knowledge. Knowledge graphs, by contrast, are structural knowledge models that explicitly represent knowledge and, indeed, allow us to detect implicit relationships. In this talk we will demonstrate how LLMs can be improved by Knowledge Graphs, and how LLM's can augment Knowledge Graphs. A perfect couple!
Simplify complex data transformations in the Snowflake Data Cloud
We will look at how StreamSets enables data engineers, data analysts, and business users to quickly and easily build data transformations in the Snowflake Data Cloud by using a no-code UI to eliminate tedious SQL coding and describe best practices, including leveraging pre-built processors, automating data drift detection and handling, and improving visibility and control across all transformation jobs.
Creating complex data transformations can be time-consuming and error-prone, resulting in delayed data delivery. There's no room for slowed-down data and analytics projects in today's competitive environment.
Join us to discover how you can simplify complex data transformations in Snowflake using StreamSets Transformer for Snowflake.
Rapid cloud data migrations with Confluent Cloud
In this talk I will walk you through how to execute hybrid and multi-cloud data migrations between heterogeneous data systems using Confluent Cloud for streaming ETL. We will discuss how to use this toolset tactically for rapid results, while using the infrastructure as a solid starting point to a long-term strategic capability for real-time data processing within your organization.
Augmented Analytics:  Evolve or be left behind
Do you still manually annotate insights or struggle to communicate them to non-technical users? In this session, we will show how augmented insights can be quickly generated and leveraged at every level. Uncover automated content generation with forecasting, smart insights, data explanations, and narrative text generation, so your organizations can make better decisions more easily.
Building an AI Programme to Enhance your Customer Data
Join this session with Lani Kakiet, Principal Solution Consultant at Treasure Data, to explore the practical applications of artificial intelligence and machine learning in leveraging customer data. The Customer Data Platform (CDP) not only aggregates data from various touchpoints but also employs AI and ML for insights, predictions, and enhancement. This ensures a comprehensive understanding of your customer base. Our presentation will demonstrate how teams with diverse skill sets can effectively utilise AI and ML to contribute to a holistic 360' customer view. Additionally, we will address common misunderstandings about AI/ML and provide strategies for avoiding them. Discover how you can unleash the complete potential of your customer data!
School attendance: How Lakehouse architecture is making a real difference to schools and children in England
The product has paved the way for a paradigm shift in the department so that data is seen as a driver for change - critically informing timely policy interventions and where data is used for innovative exploration rather than solely for statistical publication purposes.
-	currently around 6 billion records in the data lake"
In numbers:
-	14M individual records a day ingested into the Department ' over ' billion a month"
-	around 19,000 fully automated bespoke dashboards"
-	over 18,000 schools (85% of all eligible schools) have volunteered to be part of this initiative"
A pupil's attendance has a significant impact on their attainment, behaviour, and mental well-being. Hence, improving school attendance in England is a key priority for the Department for Education. Neil will talk about a new transformational data process that provides daily systemic analysis on pupils' attendance to the schools, local authorities, and Multi Academy Trusts, making it easier for them to notice patterns of absence and intervene swiftly. This also allows Government to adjust and enhance policies to support schools to tackle persistent absence.
Much of the success of this product is also due to cultural change in ways of working between policy and data teams who worked hand-in-glove to achieve the outcomes rather than as separate entities with different agendas. This has necessitated a total redesign of our data architecture and associated data platforms, as well as expediting modern technology and Lakehouse infrastructure ' to swiftly process and analyse unprecedented data volumes in the Department.
-	at a peak, around 80 million records on days of industrial action, automated to take account of non-participation bias - to enable publishing, at 4 pm on the first strike day, the official statistics detailing the impact of the day"
Becoming Data-Fit: Performing Mission Critical Work at the Speed of AI
AI is has become the major driving force accelerating how mission-critical business and operational work gets performed. But there are foundational aspects to making data "fit" for AI in order AI to perform well. Data needs to be trusted for a single version of the truth to be employed responsibly with AI and to run mission-critical operations reliably. Embedding more AI into mission-critical operations means curating and blending data across business functions to empower all teams with accurate content generated with AI, and without compromising business agility or compliance when personalizing data for every customer interaction.
Join this session where we discuss the fast-paced changes organizations are now making to become 'data-fit' and leverage their data together with next generation AI capabilities. You will hear from two industry experts who will share insights on how work is being transformed by embedding AI technologies into day to day operations across energy, banking, insurance, healthcare and public sector organizations. Ajay Vohora, VP for AI, Data & Analytics will also share behind the scenes insights on approaches being used to accelerate adoption of new AI data products, hybrid cloud architectures and tools necessary to drive data to AI to perform mission critical work.
Streamlining Operations: Johannesburg Stock Exchange Harnesses Data Virtualization for Real-Time Validation of Billions of Dollars in Trades
The Johannesburg Stock Exchange (JSE) has undertaken a groundbreaking initiative by implementing Denodo as a dynamic data virtualization layer. This strategic move has allowed the JSE to effectively streamline its expansive data ecosystem, orchestrating real-time data convergence from disparate systems. Through the integration of nearly 194 data points, the JSE has achieved connectivity with diverse data sources, including pivotal streaming sources vital for Post Trade settlement activities.  Discover how this innovative approach not only enhances precision, but also sets new standards in accurate share price measurement.  With an unmatched accuracy level of 100%, JSE's adoption of data virtualization is delivering a competitive advantage that is redefining the landscape of financial operations.
Revolutionising Analytics to Propel Fresha Into the Future
Building solutions with Microsoft Fabric
Microsoft Fabric is transforming how everyone accesses, manages, and acts on data and insights by connecting every data source and analytics service together'on a single, AI-powered platform. In this session, join Mark Pryce-Maher and Craig Porteus as they take a deep dive into Microsoft Fabric,  explore how it enables developers build innovative solutions and share insights from real-world customer projects.
Fueling Fujitsu’s Data Skills and Talent Evolution
-	The mindset shift modern teams are embracing around apprenticeships: who they serve and the value they bring"
Don't miss out, as we explore:
Every organisation is facing retention challenges and fighting the war for talent, especially data teams (and data skills for the broader business). But you might be looking in the wrong place for solutions -- your valued people are already there, with the needed domain knowledge. Funded by the levy and harnessing the power of applied learning, professional apprenticeships across digital, data and tech can help tap into this pipeline ready to be upskilled and re-skilled. After all, the future of learning is working.
-	How the creation of the Digital Data & Cloud (DDaC) division enables Fujitsu to radically rethink skills management and the career progression of their people"
-	Fujitsu's first upskilling evolution: The Data Academy"
Governing data when data is your product
Governing data is never easy but can be a lot more difficult when your product is data.  In this session we will talk how governance helps makes data-driven decisions, the value it brings and how to avoid losing a spacecraft!
Analytics Enlightenment: A Revolution of Technology, Community, and Automation
In the era of data-driven decision-making, 'Analytics Enlightenment' represents a transformative journey encompassing three crucial pillars: Technology, Community, and Automation. Join us as we explore how cutting-edge technology is reshaping analytics, how vibrant communities of data enthusiasts are fostering innovation, and how automation is streamlining insights generation. Discover how this revolution is empowering businesses, organizations, and individuals to harness the true potential of data for faster, more informed choices. Get ready to embark on a data-driven enlightenment that's shaping the future of analytics
Ira Watt speaks on his experience implementing automation with the latest technologies with a constant focus on community.
Help! How do I teach my AI to be responsible?
Responsible AI implementation covers a lot of elements. By teaching your AI to be responsible you are ensuring that your models are interpretable and explainable which is an integral part of telling the story behind your data and the decisions that are made
From Data Mess to Data Mesh – a technical deepdive into our Data Platform Kitchen – how integrated self-serving data platforms enable data transformation & drive business value
The base for a company's successful data transformation is a mature data platform. It not only offers many advantages for the individual work experience of engineers, but also drives real business value. This presentation will give an overview on learnings while building a mature self-serving data platform in the hyper growth environment of the world's leading meal kit company and present advantages for its users and the business in general:
- First and foremost, the platform provides out-of-the-box ingestion of both batch and streaming data. This means that data can be collected from various sources, such as operational systems (databases and kafka), manual sources and stored in the platform in near real-time. The ingestion process is automated and requires minimal configuration, allowing data producers and business users to focus on analyzing data rather than managing it.
- Outlook: A mature data platform builds the base for further automation and ML features.
- Finally, the platform is highly scalable and flexible, enabling us to adapt to changing data needs. It can easily handle large volumes of data and is compatible with various data storage and processing technologies like spark and snowflake.
- Hellofresh's self-service data platform offers a robust set of technical features that enables the company to manage our data more efficiently whilst enabling quicker time to actionable insights.
- Another key feature of the platform is its focus on governance and cost control. The platform includes built-in controls and policies that ensure compliance with regulations and internal policies, such as data retention and access controls. This helps to maintain data quality and security while ensuring that costs are kept under control.
- Possible to add: Business case showcasing increased efficiency and less errors in the production process thanks to valuable and fast data insights.
- The platform also offers a user-friendly configuration for creating data products. Users can configure data pipelines and workflows through a simple command line interface without requiring any programming skills. This makes it easy to create and deploy data products such as dashboards and reports.
Bridging the Gap between Business and Technology, and Breaking Silos to Deliver Value.
Are you in a technology team that are delivering high quality data platforms but feeling unrecognised by the business stakeholders? Are you in a business insights team feeling you have to create your own 'shadow' IT off a patchwork of data sources because the core platform is inaccessible? Let's discuss how to break down those silos and recognise the contribution of each other to deliver value to your customers.
Unlocking the Power of Data Integration:  Modern Strategies Unveiled
In this session we delve into the world of Data Mesh, Data Fabric and Data Democratization, exploring their pivotal role in shaping data management and integration strategies.  Uncover the challenges, options and latest trends that dominate the market, and the potential ROI and impactful use cases of these cutting-edge models.
Discover how to make informed decisions tailored to your organization's unique challenges and toolsets.   Learn what strategy suits your business best and gain insights into crafting a seamless agile, governed, secure and real-time data delivery model.
Join us to unlock the power of data integration and set your organization on the path to success in this data-driven era.
You Can Have Your Cake and Eat it Too – Best Practices in Data for Sustainability and Quality
Achieving data excellence is not only good for business but it can also be good for the environment. As organisations are building out a foundation for data trust, the concept of 'knowing your data'' should also be balanced with managing the hidden costs of storing and hoarding data. The increasing petabytes of data storage across on-prem and cloud leave a far greater carbon footprint than we realise.
Attend this fireside chat featuring Roberto Maranca, Energy Management Data Officer from Schneider Electric and Peggy Tsai, Chief Data Officer from BigID to learn how you can uncover a path to data-driven ecosystem:
-	Automate Data Foundation: Streamline data cataloguing and classification, empowering better data understanding and decision-making."
-	Manage Data with Sustainability Principles: Incorporate sustainable practices in data lifecycle management, optimising storage and reducing energy consumption."
-	Integrate Data Retention Policies: Align retention policies with metadata management, ensuring compliance across teams and minimising unnecessary data accumulation."
Empowering a data driven culture: Self Service, Data Literacy and External analytics
As Business Improvement Director at Wilson James, Tom Giles discusses the journey of building a data-driven organization through the use of Domo'from unlocking information from multiple platforms to changing the culture around data.
Discover how Wilson James has helped to change the cultural mindset by implementing an end-to-end analytics platform and becoming a market leader in their space. Data has become the forefront of new revenue opportunites within the business and clients have new mechanisms of accessing and employing data.
How Tenable Leverages Snowflake and Monte Carlo to Elevate Data Quality, Monitor Application Performance, and Optimize Queries
Data Engineering Manager, Tom Milner, walks through how Tenable uses Monte Carlo's data observability platform and Snowflake's data cloud to create highly reliable data pipelines at scale. In addition to sharing data quality best practices, he will also highlight the unique way he has applied Monte Carlo custom monitors to enable the team to monitor the performance of their Snowflake queries AND the operations of their cyber security application.
Tenable, a cybersecurity company that enables organizations to effectively manage and measure their security posture, leverages a next-generation data platform to ingest complex streaming data, surface insights to customers, and power machine learning algorithms, all while maintaining high levels of data quality. So, how do they do it?
The perfect blend of smart people and smart technology for transformation
Peter Jackson, Chief Data & Technology Officer at Outra, will delve into their evolutionary journey of their Data Cloud transformation using Snowflake to develop and deliver robust data products and innovation to rapidly meet customer needs and to stay ahead of the market. Today, the organisation is harnessing Snowflake's capabilities to fuel their customer-facing applications and visualisation tools, leveraging secure data collaboration to open up new revenue streams, and streamlining the development, training, and deployment of advanced ML models. Join us to learn more about this remarkable transformation journey that is bringing robust and innovative data products to the industry.
Enabling Data Warehouse performance on the Data Lakehouse
Data lakehouses provide flexibility and cost efficiency at the expense of predictable high performance.  Data warehouses provide predictable high performance but are inflexible and expensive.  Join our talk on learn how to get predictable high performance on your lakehouse while preserving flexibility and cost efficiency.  Doing so is an imperative as we go down the path of using AI to eliminate barriers to asking questions of the lake and democratize access. Current approaches are driving cost efficiency but still unable to cross the performance bar regardless of whether they are SW approaches or repurposing GPUs.  We will discuss how purpose-built accelerators can provide 10x performance improvement / dollar while avoiding the need to rearchitect your data lakehouse deployments.
From Sensors to Streams: A Energi’s Real-Time Monitoring of Telemetry from a Massive Grid
The Future of AI and BI: Fireside chat with Praesto Consulting and AgileTi
The Era of AI
AI may well represent the most consequential technology advance of our lifetime. Like no technology before it, AI advances augment humanity's ability to think, reason, learn and express ourselves. In effect, the industrial revolution is now coming to knowledge work. And knowledge work is fundamental to everything. In this session Alex & Adelina will cover the current AI landscape in Microsoft, how we design build and run this powerful technology in a responsible manner, and highlight some interesting use case where the technology is being applied.
Scaling PostHog to 5m analytical queries and 10bn events a month with Clickhouse
PostHog is a single platform for product analytics, session replay, feature flags and data warehousing. A few years ago, we moved from Postgres to Clickhouse, and since then we've scaled nearly 100x. I'll cover what makes Clickhouse great at what it does, some of the gotchas, and some of the tools we've developed to support Clickhouse.
How Maersk adopted a modern data stack and GenAI on a budget!
Maersk is a global leader in container shipping, logistics, and energy. With an extensive network of offices in 116 countries, over 900 vessels, hundreds of warehouses, and a modern fleet of aircraft. Maersk provides comprehensive shipping services across the globe with commitments to achieve decarbonisation and reach net-zero emissions.
Learn how Maersk is building the next generation data platform for unified analytics on Dremio's Open Data Lakehouse, on a budget.
Join this fireside chat with Mark Sear, Director of Data Analytics and AI/ML at Maersk, and Tomer Shiran, founder and chief product officer at Dremio, as they talk about Maersk's journey in building a next-generation data platform for solution development using Dremio's open data lakehouse and Generative AI.
Get Insights from Your Data no Matter Where it Resides
What does it truly mean to be data centric? How do we bring data together that has all too often been disparate silos and not possible to run the analytics workloads that we need to run? How do we expose critical data to workloads to derive value? Having the right data strategy and infrastructure allows you to pull data from what would have been siloed or worse, thrown away. New technologies allow you work with your data no matter where it lives, for example capturing data from ancient systems.  Learn how to use your data to make decisions, and how to create a winning data strategy.
Street Cred, making generative AI work for our business
Imagine a world where generative AI can help you make better decisions in aviation, from planning flights to managing risks. But how do you ensure that the AI is trustworthy, reliable, and realistic? In this talk, we will dive into the exciting and challenging aspects of applying gen AI to the aviation domain, where safety is paramount and data is crucial
Data Observability Use Cases: A Look Beyond Data Quality and Incident Management
Data observability has emerged as a new product category to help organizations automate their data quality and pipeline performance by using techniques adapted from observability and application performance tooling. For many, this is a new technology to learn and integrate within their data ecosystem, and the use cases are still unfolding. In this session, we will explore the most common use cases for data observability beyond incident management and reactive response to data downtimes. Attendees of this session will learn how data observability can help them modernize their data stack from examples we have learned from the field and our customers.
Empowerment through Data Literacy
The term data literacy has a lot of buzz and hype around it, but what is it?  What does it truly mean?  Come join Jordan Morrow, known as the Godfather of Data Literacy, as he discusses this important topic.  You will learn the end goal of data and analytics, the definition of data literacy, and a strategy for building data literacy for yourself and your organization, helping you to become more data-driven.
The Art of Insight: Unleashing the Persuasive Power of Visual Analytics
This session delves into the fascinating intersection between analytics and creativity. We will outline how data visualisation can transform complex information into compelling and persuasive narratives and explore the role creativity plays in unleashing the full potential of analytics .
Bridging the Gap: Integrating Knowledge Graphs and Large Language Models
We also examine how language models can enhance KGs through knowledge extraction and refinement. The integration of these technologies presents opportunities in various domains, from question-answering to chatbots, fostering more intelligent and context-aware applications. Don't miss it!
This talk explores the integration of Knowledge Graphs (KGs) and Large Language Models (LLM) to harness their combined power for improved natural language understanding. By leveraging KGs' structured knowledge and language models' text comprehension abilities, we can leverage the domain-specific'and potentially sensitive'data together with the general knowledge of LLMs.
From 0 to 300 mph Towards the Promised Land
As the volume and velocity of data in motion continues to increase, the challenge becomes being able to move your team at the same pace. After implementing technology to capture data from various high-frequency sources such as financial applications, sensors and IoT devices, teams often find themselves struggling to build and roll out best practices quickly. They inevitably fall behind on the performance and scalability demands of the business.
In this session, Mike Rosam and Tun Shwe will share their experiences of building data teams at McLaren and fast growth startups. They will take you on a journey of how they navigated their way from the old batch world to the new streaming world, where real-time decisions are enabled by stream processing and are within the reach of every data team.
Attendees will learn the common sources of friction against streaming technologies in organisations, be able to identify the pain points that lead to streaming adoption, prioritisation based on data maturity and how to gain a competitive edge by focusing on culture and value. So, buckle up and join us on this high-speed adventure to the promised land!
How to govern your Data Mesh with Data Contracts
This informative session offers a practical deep-dive into the pivotal role of data contracts within the Data Mesh framework - a modern approach to data architecture that decentralizes data ownership, promoting team-led, domain-oriented data products.
-	Introduction to Data Contracts"
Next, we dive into the core processes at build, deploy, and run time that underpin the enforcement of these data contracts, showing how Witboost, Agile Lab's platform, can help to define, implement and enforce them, with full automation.
Following our session you will learn more about:
We begin by demystifying 'data contracts' - explicit agreements that delineate the structure, quality, and semantics of output ports. These contracts are crucial for ensuring smooth, efficient and governed data interactions within a Data Mesh. We'll shed light on the practical benefits of data contracts through real-world examples, highlighting their capacity to enforce consistency, facilitate interoperability, ensure reliability and instil trustworthiness.
-	Data mesh challenges -> Governance"
-	How Data Contracts can create trust and governance in a Mesh by enforcing Semantic, SLA and Quality"
-	How Witboost helps companies create and automate Data Contracts"
Our focus is on offering pragmatic insights and strategies for effectively managing data contracts within Witboost and your Data Mesh implementation, applying computational governance principles.
Data Product 101: Unlocking the Power of Data for Transformational Insights
Join Anthony Deighton, Data Products General Manager at Tamr in an enlightening session on data product strategies and best practices for the modern business. This informative talk goes beyond the surface and delves into the four principles of good data products and demystifies the complex process of developing data product strategies.
Organizations are discovering the immense value of data products in driving strategic decision-making and unlocking transformative insights. But what exactly are data products, and how can they revolutionize your business?
Using real-world examples and industry-proven techniques, Anthony will provide valuable insights into the essential components and methodologies successful organizations employ. Regardless of your organization's stage in the transformation journey, this session will empower you with the tools and techniques to harness the power of data products to drive innovation, enhance customer experiences and foster your organization's competitiveness.
How to use Data Observability to Improve Analytics and AI, while Saving Money and Staying Compliant
Come learn how Data Observability empowers CDOs, data leaders, and data engineers to optimize their analytics and AI investments, reduce costs, and ensure compliance through data reliability. Using real-world examples from global brands, we'll demonstrate how data observability continuously optimizes data pipelines, increases accuracy in analytics, and delivers trusted data to fuel existing and new Generative AI models. The kicker? You can get going today for free, by leveraging spend intelligence to identify inefficiencies and optimize cloud resources for a net ROI gain via significant cost reduction. Finally, learn how you can also immediately reduce the cost and operate your legacy Hadoop investments, while optimizing for a cloud migration strategy to Databricks, Snowflake, and more
Artificial Intelligence, External Data and the next evolution in analytics and decision intelligence
Recent breakthroughs in Artificial Intelligence will have profound impacts on analytics and decision intelligence. In this talk we will discuss a handful of real-world use cases for artificial intelligence in the analytics stack. From improving data quality to discovering the best data to use in your projects, we will discuss the fast-moving changes you need to be prepared for.
Safely Using Gen AI With Active Metadata and Data Fabric
Enterprises looking to benefit from Generative AI and LLMs face major and very valid security, accuracy and training concerns when considering using the available solutions. Introducing active metadata from a data fabric will enable LLMs to reduce manual data management implementation and transform enterprise data use. At the same time, the data fabric can protect data and analytics leaders from revealing competitive advantages to shared LLM learning models. Attend the session to find out more and see some real life examples.
Navigating the Challenges of Operationalising AI Automation in Data Cataloguing
Join Ivor Lawrence VP, Firmwide Data Office, Morgan Stanley for an insightful session on navigating the complexities of implementing automated data cataloguing in today's data-driven world. Data is the lifeblood of organizations, and efficient data cataloguing is pivotal for maximizing its value. In this session, Ivor will guide you through real life challenges and you'll gain practical insights and best practices to successfully implement and leverage AI automation within your organization.
Enabling Data Innovation with a Data Security Platform
In this session you will learn about our journey to greater visibility and faster data access - from scoping to implementation and internal communication.
Do you know who has access to your customer's data? How many data sources do you have? Where the sensitive data is stored? All those are crucial questions when you are a data-driven company.
At Gong, data is our primary asset for empowering our customers with strategic business insights. We wanted to ensure that despite the top importance of keeping our customers' data safe, our developers will still be able to drive innovation with data.
AI Governance: How to overcome the challenges of embracing generative AI technology in a rapidly evolving regulatory landscape
This session will challenge the popular belief that governance hinders innovation and slows teams down. Instead, we will show you that effective partnering between tech and legal, robust feedback loops and a joined up lifecycle-based approach underpin a successful data culture.
How Data-as-a-Service Embraces Business-IT Alignment for Gen Re
How does a global financial services organisation bring measurable advantage and consistent returns from Data-as-a-Service?
-	Prioritize self-serve enablement and easy adoption for business users as a mandatory success criteria"
-	Build close and empathetically Business-IT relationships by establishing shared programs of work that align with business objectives and goals"
-	Invest in a cloud-based scalable data architecture that can provide easy access to business users"
How do you enable business users at scale and drive effective adoption of new tech?
In this executive-level session, we'll present an overview of three years of significant value growth achieved through enterprise data services that are critical to business success. This growth has been achieved within a newly revived culture that emphasizes strategic investments in modern technology solutions.
-	Continuously demonstrate the value of Data-as-a-Service to the board to secure ongoing funding and capabilities"
-	Strike a balance between leveraging expert external resources and developing internal talent to deliver both long- and short-term data services"
Decentralizing Data Access at Galp: The Role of Dremio in Driving a Data Mesh Paradigm
Dremio supports our entire strategy concerning self-service data exploration and analytics, allowing access to our hub's data and federating other data sources, all in a performant, secure, and governed manner. We anticipate an increase in the organization's data literacy, and in the near future, we hope to move towards data mesh concepts, with Dremio being one of the components that will enable us to accelerate the adoption of this organizational data paradigm.
Galp data strategy is built upon the pillar of democratizing data access and analytics, promoting decentralization when it comes to data product development. As the democratization of data access continues to grow, and data becomes a central component of our business operations, more functional teams are involved in data and analytics management with the aim of simplifying and expediting decision-making processes. From the beginning, Galp's strategy has implemented around the adoption of a decentralized data architecture, where the Ulysses platform (Galp Enterprise Data Hub) serves as the central piece managed by our data engineering team, but with analytics and data science teams distributed across various business areas.
DQ/Catalog/Marketplace, the next is now platform play!
What do you get when you combine DQ, Catalog and Marketplace? An ethereal D&A experience.  This advancement in integration powers up both the data and the end users experience. Adding a Marketplace for collective intelligence about Datasets, third party data and AI models ensures that the model is using the right data and begins to alert for things like data drift, PI and biasness.  Producing data as a product, providing data value and guardrails around critical datasets has never been so real and inviting'
How EQT is using Location Intelligence & AI to unlock strategic value in the portfolio and beyond
Motherbrain is EQT's proprietary AI driven investment platform which uses AI, ML and advanced analytics to help deal teams and portfolio companies drive value across the ownership lifecycle from sourcing to due diligence to holding. Hear how Data Scientists at Motherbrain Labs are using Location Intelligence platforms like CARTO to accelerate strategic problem solving directly at the portfolio level and beyond.
Semantic Data Product
The Semantic Data Product talk explores how Large Language Models (LLMs) enrich Data Management tools, enabling a cohesive Data Fabric vision. Discover how LLMs can provide higher levels of automation and improved data quality. Join us to learn how to unlock the full potential of your data.
Breaking Barriers in Data: Explore Limitless ELT Integration
The Data Movement landscape is changing, it is not enough to just move data. You need to be an extendable platform. What does extendable mean? In this session, we will show you how Airbyte is the only ELT tool that is truly extendable because of our Open-Source roots. We will show how you can build a connector in our UI, how a developer-friendly interface will enable you to interact with Airbyte programmatically through the Airbyte API and Terraform provider, and how you have control of the airbyte platform end-to-end.
Simplifying Streaming Data Transforms with Wasm
The majority of stream processing work is spent on mundane transformation tasks like data scrubbing, normalisation and filtering. Yet to perform these relatively simple tasks involves standing up multiple distributed systems that add complexity and take time to learn.
Worse yet, once you're done, you end up ping-ponging data back and forth between storage and compute just to remove a field from a JSON object. To the data engineer, it can feel like an endless game of system whack-a-mole just to start the interesting work of actually understanding the data. Fortunately, help has arrived in the form of WebAssembly (Wasm), which enables users to create transformation modules ' in the language of their choice ' to perform fast data transformations on topics. By shipping these computations to the storage engine, developers can codify business practices like GDPR compliance or schema normalisation, with near native-level performance at runtime.
In this talk, Tristan Stevens, Director of Customer Success at Redpanda, will provide an overview of a WASM-based data transformation architecture, and show how it can simplify as well as boost the performance of real-time applications and data pipelines.
The power of radical transparency: How to turn your whole data team into problem-solving ninjas.
Data teams are fantastic problem-solvers but all too frequently find this skill is under-appreciated. In this session we'll be showing you how you can turn your data team from dashboard builders into problem-solving ninjas using the power of radical transparency to work directly on your organisations' biggest challenges and providing the maximum return on their time.
Why Diverse Teams Win – and How to Drive Change
Boardrooms and businesses are changing and those that embrace the diversity imperative faster will succeed better. Rebecca and Solange will highlight the tangible advantages offered by driving meaningful change, such as higher employee engagement and improved performance. But like all transformation processes, companies across the board will face significant challenges. Attendees can expect to leave armed with actionable insights into effective strategies for embedding diverse teams within their own organisations.
Check Before Tech: Beware of Dirty Data!
As well as an entrepreneur, Susan is an industry thought leader, an influencer and a global speaker. She has been listed in the DataIQ100 for the last two years, as well as winning DataIQ Data Champion 2022. She's also a published author of Between the Spreadsheets: Classifying and Fixing Dirty Data and has published her own online course: Fixing Dirty Data ' The Basics of Data Cleaning. In addition to this, Susan also has a TEDx Talk Say NO to NO, which has amassed 3k views and counting.
Susan has created her own methodology: the data COAT. This has helped companies across the globe save time and money thanks to seeing the value in cleaning their 'dirty data'.
Takeaways:
'            Dirty data to beware of
She will take you through the reasons why you need to clean your data before any implementations or new tech, and the problems it can cause when you don't.
'            The data COAT
'            Spot-checking your data
'It's ok, the AI/software/tech will fix our data problems'.  No, it really won't.
The thing about AI, machine learning, software and tech, is that guess what - it needs clean data to learn from, whether that's in the form of training data sets, rules or master lists.  And how do we get these clean data sets?  We use people.  And not just any people but experienced people and subject matter experts.  It takes a village to make and keep your data clean.
Susan Walsh is The Classification Guru. She has been cleaning, classifying and fixing dirty data for over a decade and set up The Classification Guru Ltd to solve dirty data problems in the procurement world.
Data Products Done Right: The New Way to Deliver Data Value
Many enterprises today face a data dilemma: long time to insights, limited data access, and data quality that's questionable at best. Data Productization is the answer to this problem.
But what is a Data Product to you?  In this fireside chat, the authors of the new book, Data Product for Dummies, and an esteemed panel of industry leaders discuss the definition of Data Products and how to build and manage them so they can create value for your organization.
Bonus: get your FREE copy of the new Data Products for Dummies book, which gives pragmatic guidance to help the next wave of practitioners and adopters generate enormous value - without so many battle scars.
Host bios:
Sanjeev Mohan is Principal at SanjMo and a former Gartner Research VP for Big Data and Advanced Analytics. With expertise covering all things data, including analytics, data governance, data management, and data observability, he has published many white papers and is a prolific speaker at conferences and events worldwide.
Guy Adams is CTO and co-founder at DataOps.live. He is a passionate advocate of #TrueDataOps and the #1 Snowflake Data Superhero globally. He was a founder of the #TrueDataops Philosophy (www.truedataops.org) and author of DataOps for Dummies and Data Products for Dummies books.
Driving Customer Empathy with Data: How OVO Generates Cost and Energy Savings for Customers through Data Observability
OVO, one of the UK's largest green energy retailers, is not your typical utility company. On a mission to tackle the climate crisis, they empower their customers with data to reduce their carbon footprint (and their bills), while also leveraging advanced data products to invest in science-based carbon reduction innovations. What's the key to powering OVO's success? High quality data.
Data Director at OVO, Katie Russell, joins Monte Carlo CEO, Barr Moses, for an electrifying fireside chat to discuss the evolution of data at OVO, how they aligned their tooling decisions to company-wide KPIs, and why data observability is critical to their mission of helping customers reduce costs - and their carbon footprint - with reliable data.
Customer Experience: The Intersection of Trust, Personalisation, Compliance and Reputation
When a measurement of success for companies is growth, the currency is customer experience. Ensuring customer data is handled securely enables effective personalisation, develops a continued trust, credibility and market standing.
Join Mike as he discusses how an organization can gain executive alignment to ensure customer experience is a focus of the business roadmap and dives into:
-	Trust and Loyalty"
-	Personalisation"
-	Legal Compliance and Reputation"
Activating Metadata: How Contentsquare Utilizes Atlan for Modern Data Governance
Let's face it, we ask a lot of our data and analytics teams. They need to move faster! But carefully' They need to decentralize to meet the needs of the business! But maintain centralized best practices... Join Kenza Zanzouri, Data Governance Strategist at Contentsquare and Austin Kronz, Director of Data Strategy at Atlan as they share how Atlan enables organizations to govern their data ecosystem. Hear how the Contentsquare team ensures data is easy to find and access, and that both data producers and consumers can trust data is accurate, consistent, and compliant with defined standards. Achieving this balance is the key to making data-driven decisions with confidence.
Back Market’s Journey to Self-Service
Will AI Destroy Data Value Chains?
Join Dataiku's Field Chief Data Officer Shaun McGirr as he explores how we can ensure AI is cheap, safe, and useful, rather than letting it stray to become unhelpful, or even worse, harmful to data value chains. In this talk, Shaun will explain: (1) The common data value chains, and what threatens them (old and new). (2) How to get unexpected value driven from AI to fully outrun traditional ways of generating value from data. (3) The first steps to escape common sources of paralysis on the road to cheap, safe and useful AI.
Harnessing Website Cookies: Unveiling their Role in Combating Online Threats
In this enlightening speech, we delve into the intriguing world of website cookies and their pivotal role in bolstering online security. Exploring beyond their seemingly innocuous presence, we uncover how cookies serve as essential tools in the battle against digital wrongdoing. By analysing user behavior and preferences, cookies empower cybersecurity and compliance experts to detect and prevent malicious activities, such as unauthorised access and data breaches. Join us to uncover the synergy between cookies and cutting-edge compliance measures, as we highlight their invaluable contribution to creating a safer online environment for all.
How Harrods hits profitability targets with Data Science and MLOps
Carys Lees, Head of Data Strategy at Harrods, and Gerard Harvey, Solutions Manager at Ascent, will share the journey of building a data science capability in Britain's leading luxury retailer. Tasked with delivery of lofty targets in terms of business value, Carys shares why now is exactly the right point in time for Harrods to capitalise on their data and how they went on journey to delivering tangible benefits to the business, and Gerard will discuss the groundwork needed for successful Data & AI solutions and the importance of automation within MLOps to free up time to focus on critical Machine Learning projects for sustained delivery of business value using data and enabling into OpenAI use cases in the future.
AI is the future we can’t predict.
AI is a future we can't predict, which makes equal representation in the field more crucial than ever. However with women accounting for less than 32% of the Data and AI workforce, AI is far from equitable. Join our panellists for a discussion about the real-world consequences of gender disparity in AI, the urgent need for fair and inclusive technology, and what we can do to make AI better for everyone.
The Top 10 Analytics Mistakes
In today's data-driven world, analytics plays a crucial role in the success of businesses. However, numerous organizations fall into common pitfalls when it comes to extracting value from their analytics efforts. Join Adam Greco, a prominent figure in the analytics industry and Product Evangelist for Amplitude, as he sheds light on the top ten mistakes that organizations frequently make in their analytics initiatives.
Key Takeaways:
- Uncover the key analytics pitfalls and learn how to steer clear of them.
- Draw from Adam Greco's wealth of experience in diverse analytics programs.
- Apply best practices to optimize the impact of analytics on your business success.
- Gain practical insights to effectively strategize and utilize data for growth.
Protecting Privacy in the Kingdom of Data: A Guide for Data Engineers
I will examine real-life examples of privacy violations to emphasize the importance of privacy for data owners. Towards achieving privacy compliance, I will teach:
If data is king, then privacy is its crown jewel. Over the last two decades, I've worked as a technical leader in the data domain and have experienced first hand the importance of balancing the collection of valuable data with personal privacy protection.
-	Different techniques to safeguard personal information, including"
anonymization, deliberate data decay, and differential privacy.
-	How and where these techniques could be applied"
Additionally, the talk will explore current privacy threats and the role of data engineers in ensuring privacy and security in handling personal and sensitive information.
By the end of the talk, you will understand privacy challenges and learn practical solutions you can apply in your work. I believe that with data becoming increasingly central to our lives, privacy and data are equally important in the kingdom of data management.
Data Privacy and Governance: assessing risks and implementing best practices into AI
AI offers many opportunities for productivity, effectiveness, and innovation if implemented properly. AI does, however, also present serious concerns about people's rights and freedoms as well as compliance challenges for organisations.
Although the need of incorporating data protection by design and default into an organization's culture and operations is exacerbated, doing so may be more challenging due to the complexity of AI solutions.
Thought must be given to legal issues and data protection principles. For example, the principles of purpose limitation and data minimisation appear in conflict with machine learning solutions that require big data sets. Similar challenging issues can arise when considering how to ensure individual rights, mitigate discrimination, and make sure processing is transparent.
Risk assessment and mitigation must begin with the design phase because trying to implement a compliance framework as a last-minute add-on rarely satisfies requirements across the board.
This talk will focus on practical steps to follow to assess the risks an AI project can pose and how to mitigate these to deliver better-quality products while protecting customers' privacy.
How data mesh impacts data security
Data mesh is the first federated approach to data. Federated by default and by design. This results in a shift of responsibilities from a central data team to data owners and business experts.  Where data quality is often used as a tangible example, data security is often unjustly neglected. So how does data mesh impact data security?
Data security is the process of safeguarding data throughout its entire life cycle to protect it from corruption, theft, or unauthorized access. In order to build thrustworthy data products, data owners must prevent unauthorized write access. They should also enable and reassure compliant and ethical use of their data.
During this talk, we zoom in on the data security responsibilities that shift to business experts and we explain how you can enable your data owners to take these responsibilities into their own hands. At the end of this session, you will know how data owners themselves can foster innovation with their data while keeping the data usage compliant.
Panel Debate: This is what winning with data looks like
Landing a successful data or AI project is challenging. With so many potential stakeholders, components and intersections to control, delivering the hoped-for outcome is never a given.
When it happens, a primary success factor is usually a senior data leader at the helm, combining positive politics with domain expertise to get a programme across the line.
In this panel session, three high-profile brand-side practitioners will share their experiences, insights and tips around how to ensure you win with data.
Data saves lives: How better use of data in healthcare will make us all better advocates
Inequality in healthcare is driven by a lack of information, representation, funding and research. Just 1% of all healthcare research and innovation is invested in female specific health conditions. How do we begin to readdress this balance? Natalie Cramp, CEO of data company Profusion and Chair of Women in Data's Health Group will be joined by experts from Boots and NCR to discuss how better use of data could be the key to better healthcare for women.
During this session, they will discuss how the knowledge we gain through data analysis projects will empower women to advocate for their own, and their loved one's healthcare. Through more informed advocacy, culture and attitudes towards talking about, researching and addressing illnesses that predominately impact women will begin to change.
BBC Studios: Introducing Data Mesh in a Leading Creative Organisation
BBC Studios is a fast-growing content company bringing the best British stories to a global audience. As the BBC's commercial global subsidiary, in 2022/23 BBC Studios reached '2 billion in sales and returned '362 million to the BBC to invest in UK audiences.
To support the company's ambitious goals for the future, data has become a key pillar of BBC Studios' strategy, needed to help better understand our business as well create more relevant content experiences for users of BBC.com internationally. In this session, Ross Gaskell, Software Engineering Manager for Commercial Data Products at BBC Studios will be sharing the history of data at BBC Studios, insights and experience building a new data platform centred around data mesh and where next for data at BBC Studios.
Building an extensible real-time platform
In this talk, Tony will walk you through how Fanduel has built their self-service real-time event systems, used across software and analytics teams, which power internal and user-facing applications.
He will describe their fundamental design patterns, and the challenges Fanduel's data team faced, when building a platform that can serve all general eventing needs.
Practical Steps for Nurturing an Analytics Culture
Building a robust analytics culture at your organisation can be a long but rewarding journey. Join Richard in this enlightening session as he shares the practical steps taken by RX to foster a burgeoning analytics culture. Delve into the process of instilling foundational analytical ways of working, improving collaboration between commercial leaders and analytics professionals, and nurturing the growth of a company-wide analytics community dedicated to shared learning and cooperation.
Navigating the Data Evolution: Future-Proofing Your Strategy for Gen AI
This presentation delves into the strategies and insights necessary to future-proof your data approach, ensuring readiness for the emerging landscape of Gen AI and reaching higher levels of data maturity.
In a world driven by data, organizations are constantly seeking ways to harness its power to drive innovation, improve decision-making, and gain a competitive edge. As we stand on the cusp of the Gen AI era, where artificial intelligence is seamlessly integrated into our daily lives, it's imperative for businesses to fortify their data strategies to enable both Gen AI integration and achieve data maturity.
HSBC’s Data Evolution: A journey to the Lakehouse and beyond
Dive into HSBC's transformative 'Data Warp Drive' project. Shortlisted for a number of awards including the prestigious Cloud Excellence Awards - 'Data Project of the Year 2023', we'll share practical takeaways that we learned along the way to conquering complex multi-cloud data challenges. We'll unpack lessons learned in virtual data lakehouse design and migration, showcasing how we successfully delivered optimized query processing, overcame data accessibility challenges, governance and data localisation needs, and achieved significant cost savings.
-	Why the strategic decision to adopt a virtual data lakehouse design was made"
-	Learn about the challenges that we faced and lessons learned as we made our way to a lakehouse architecture"
-	What's next for HSBC - how are we pioneering change and innovation with data at the core"
Infusing AI into Enterprise Apps
Organizations around the world have come to recognize AI as the transformative technology that enables them to gain real business advantage. AI's ability to reason over vast quantities of data allows those who implement it to uncover deep business insights, augment human expertise, drive operational efficiency, transform their products, and better serve their customers. In this session, join Juliane Franze to explore how AI technology can be integrated in your enterprise applications to drive business impact today.
You’ve got to eat the good stuff before you eat the cool stuff
You've got to eat the good stuff before you eat the cool stuff
By Gethin Jones  age2 '
A lesson for us all in governing data, minimizing business risk & realizing the true value of your data
There's  SO much amazing technology out there today ' with the power of Generative AI there has never been more potential to gain incredible insights from data and most importantly drive the most value possible for your business from your data, quickly and easily.
But before we all get swept away with the excitement surrounding generative AI, spend a few minutes with me, to see how a seemingly innocent but profound phrase from a young child can help us draw parallels with the world of data & how it can help ensure that in the rush to make the most of amazing new technology, it doesn't all end up in DISASTER!
Join Rob Jackson-Jones as he helps show you how through some very simple steps you can hugely minimize the risk to your business of putting your faith in Generative AI and the exciting new world that it opens up
Data as a Product: Applying Product Management Principles to Data
The Data Engineering group underpins Elsevier's Technology strategy and helps drive the journey towards a mature data-first company. The team is responsible for extracting, matching, linking and enriching data with high quality - which is at the core of helping our customers make high value decisions with confidence.
Generative AI: BSI + DataRobot A CDO’s Must-Know Guide to Unlock Business Value
Data is The New Bullsh*t
Are you struggling to implement an analytics-graph-hub-fabric-mesh? Meanwhile, you lack leadership support, crave stakeholder engagement, and beg for proper funding?  Even though you may work algorithmic wonders with your data, it won't matter unless you explain the value in practical business terms. Hear The Data Whisperer's rollicking and riotous review of current dataspeak and some practical tips and tricks on telling your data story.
Transformative BI powered by AI
To stay competitive in the current economy, businesses need to use data democratization to gain insights through BI and analytics.
Breaking data silos, deriving 360' insights, blending data across business functions, and empowering everyone with insights can truly transform business outcomes.
Artificial intelligence is now augmenting every layer of business intelligence to be more powerful, democratizing access to insights. By adopting a modern BI and analytics platform, businesses can unlock transformative potential and uncover growth opportunities.
Join us to start your BI journey and learn how AI is evolving in the data and analytics domain to meet emerging business needs.
Here's what you can expect from this session:
- The state of data and analytics adoption
- Data and analytics challenges faced by businesses
- How AI is reshaping analytical insights
- Guide to transforming outcomes by adopting a modern AI-driven BI platform
The Rise of AI in Data Governance: What You Need To Know
AI is transforming data governance by enabling data stewards to complete tasks in an instant, implement Data Governance policies and standards in near-real time, and substantially reduce data cleansing time. On average, 80% of the data governance tasks that would once have required involvement from IT and data engineering teams can now be completed by non-technical specialists with greater speed and accuracy than ever before. Join this session to discover what AI could achieve for you, and to learn how to put the right guardrails in place to ensure maximum impact with minimum risk.
Don’t Be The Catcher On The Javelin Team
We often concern ourselves with data security when an incident has taken place. It may be in our enterprise or another company in a similar market space. We tend to focus on the issue once something bad has happened such as our data has been corrupted or exfiltrated. We add a home alarm system after there has been a break-in for example. There is a visceral reaction. Much in the same vein as when a criminal breaches our computer systems. We feel violated as a result. When we look at the healthcare profession, they treat the symptoms of an illness. Rarely do they look at the steps that lead to that illness. More attention needs to be paid to the strategic vision.
The same can be true when we look at the enterprise level. With rising cyberattacks, organizations need to ensure robust security measures to better protect their data. Zero trust eliminates trust assumptions and verifies identity/trustworthiness before granting access. Security resilience involves having a coherent plan to respond to incidents and minimize their impact. This talk explores these concepts and the importance of implementing them to defend against hackers before they can get access to or alter data. Key considerations and best practices for data professionals will also be discussed to enhance security resilience, implement a zero-trust architecture, and how security intelligence can better protect organizations.
Solving Data Problems with Design Thinking
ITV’s Data Mesh Journey: Pioneering the path to AI and ITVX, through Data Products and beyond.
Introducing Darren Wood: A Visionary Leader in Data Product Strategy
Join us in this captivating talk as we delve into ITV's Data Mesh journey over the last 18 months with Darren Wood, the Head of Data Product Strategy at ITV. With an impressive decade-long career in product development in FTSE 100 companies and a Chair of a large charity. Darren brings a wealth of experience and wisdom to the table.
In this session, Darren will share his Data Mesh journey whilst launching ITVs new streaming service ITVX, showcasing how his expertise and forward-thinking approach have contributed to shaping ITV's data-driven initiatives. Discover the invaluable learnings he has gleaned, and gain exclusive insights into the dynamic realm of data mesh implementation and its significance in empowering the thriving landscape of AI and ITVX.
Prepare to be inspired as Darren imparts invaluable lessons on driving data product success, leveraging data intelligently, and embracing the ever-evolving challenges of the television and streaming industry.
Webscale Real-time Systems: Trillions of Decisions a Second
Quantcast Edge Systems receive millions of requests a second and calculate thousands of operations for each request to make trillions of decisions a second while all these systems should work real-time and highly-available. Join us as we explore how we maintained cost-efficiency, achieved scalability, and gain insight into the architecture, tools, and infrastructure that empower such a high volume operations at this scale.
LLMOps: Everything You Need to Know to Manage LLMs
With the recent surge in popularity of ChatGPT and other LLMs such as Dolly, many people are going to start training, tuning, and deploying their own custom models to solve their domain-specific challenges. When training and tuning these models, there are certain considerations that need to be accounted for in the MLOps process that differ from traditional machine learning. Come watch this session where you'll gain a better understanding of what to look out for when starting to enter the world of applying LLMs in your domain. In this session, you'll learn about:
-	Grabbing foundational models and fine-tuning them"
-	Optimising resource management such as GPUs"
-	Integrating human feedback and reinforcement learning to improve model performance"
-	Different evaluation methods for LLMs"
A Unified Business Data Layer for Generative AI adoption and Cloud Acceleration
Connected, secure data with business meaning enabling timely insights and decisions has long been the data management 'dream', mostly unattainable or very expensive (when considering the cost of humongous human effort involved). Until data fabric design emerged and vendors like Stratio BD started offering an integrated and flexible cloud product for automation of the data discovery, virtualization, cataloguing, data governance, semantic ontologies and knowledge graphs, which has revolutionized the operations of many global banks and retailers, but still ,for many companies, remains an unexplored technology. Attend this session to learn about data fabric and how it helps to create a unified business data layer faster and cheaper than the manual way and enables the use of Generative AI for enterprises as well as accelerates the move to public cloud.
Unleashing the Power of Purpose-Built AI for Data Speed and Scale
Data is deciding the winners (and losers) in every industry. Discover what sets winning organisations apart and how they overcome the most common data and analytics challenges. Learn how data observability and FinOps help enterprises accelerate the launch of new data products and AI models.
In this session, you'll discover:
- How purpose-built AI enables speed and scale through performance and efficiency
- Strategies to turn the exponential growth and complexity of data into an advantage
- Real-world examples of how Unravel customers have achieved extraordinary results
Exploring How a fortune 100 financial Institution enabled credit card approvals in real time
Financial institutions are constantly dealing with vast volumes of sensitive data and it's crucial for them to process and act on this data in real time. In this presentation, we will discuss a real-life case study showcasing how Gathr enabled the implementation of data processing and machine learning on Spark, to accelerate the process of real-time credit card approvals.
Drawing from the experience of building a real-time credit card approval system for a leading bank, you will learn about modern data architecture, tools and methodologies, to streamline and accelerate your own data to outcome journey.
-	Step-by-step walk-through of an ML-based pipeline in Spark"
Key takeaways:
-	The key pieces of creating a real-time decisioning system"
-	A clear roadmap for developing and operationalizing models at scale"
-	Solution blueprint that can be applied to your own use case"
Optimising Monzo’s Customer Communication
Monzo's data strack contains millions of customer data points from a variety of interactions. While sorting through this can be challenging, it's important that we are able to do it efficiently and can use it to benefit our customers.
In this Fivetran and Monzo session, we'll talk about how we organise data to inform our customer communication and how we use uplift modelling to improve campaign performance by 200%.
Where AI delivers real business value
For many businesses, executive leadership is now driving the demand for AI. While that's a positive as data professionals to have the attention of the top, it's over to you to navigate how to go about it and keep everyone informed.
But rather than just diving straight in, how do you know when you have a problem suited for AI? Where in your business can AI or GenAI deliver the most value?
We're seeing businesses racing to build tools and products embedded with AI, aiming to beat out the competition or out of fear of being left behind. And while this agility and innovation is critical to remain relevant, there's a risk that efforts are not focused on the most value-add areas or problems. In this talk, Cynozure's CTO, James Lupton, who's known for his ability to translate complex technical concepts into something easily digestible, will walk through...
-	Ways in which AI can best support your organisation"
-	Help you frame this through a value lens"
-	Give you the tools & examples for how to talk with your executive leadership about this"
Pursuit of Fairness: How AI Helps Improve Human Bias in Scholarly Editorial Practice
Diverse Paths into Data: Stories from Expedia Group
At Expedia Group, we are guided by an inclusive purpose - to strengthen connections, broaden horizons and bridge divides for our employees, partners, customers, and communities. Travel opens minds and drives better understanding between people from different cultures and identities ' something the world needs today like never before. For our employees, we aim to create an inclusive and enriching environment that celebrates our extraordinary blend of backgrounds, perspectives, and life experience.
In collaboration with Women in Data, at our panel you will meet leading women from across Expedia Group whose teams use data in a variety of ways to improve our offering for travellers, and hear how those women got to where they are today. We support a huge number of career paths, from traditional Analytics and Data Science, through Data Engineering and Optimization, giving our women every opportunity to thrive and build careers anchored in the data industry.
Data Modeling is Dead! Long Live Data Modeling!
Data modeling is on life support. Some say it's dead. The traditional practices are increasingly ignored and forgotten. The result is often a loss of structure and a shared understanding of business rules and vocabulary.
At the same time, data modeling is more critical than ever. With AI's rising popularity, many organizations rush to incorporate it into their infrastructure. Without consideration of the underlying data framework, the result will be unpleasant for many organizations.
In this talk, I argue that data modeling is a key enabler for success with AI. We must return to basics and revamp data modeling to work with modern business workflows and technologies. Long live data modeling!
Panel Debate: Gen AI: What’s now? What’s Next?
Advances in Generative AI have dominated the news, the boardrooms of companies globally and the talks of Big Data LDN in the last year. In this session our expert panel will discuss the benefits and risks you need to consider when evaluating the possibility of using Generative AI in your business. They will also show how it is already affecting sectors such as Education, Finance, and Manufacturing and the many ways all businesses and consumers could be benefitting from it in the near future.
5 Steps to Strengthen Data Defense and Compliance
Modern organizations collect a massive volume of data every day. Identification and analysis of this data's use enables business operations to run more effectively through sharing and subsequently monetizing the data to increase customers and revenue. The challenge is that this also introduces cyber risk. Business data often resides both in the cloud and on-prem increasing complexity and thereby, increasing risk even further. So how do you identify the risks or potential threats? This session will identify 5 steps you can take to share data securely and understand how to stay in compliance, regardless of your industry.
Generative AI & The Modern Data Stack
Generative AI is a trendy topic - being talked about everywhere. But, what does it actually look like in practice and how can it benefit you and fit into your modern data stack? Join our session to find out!
By making data integration easier and quicker for novice and expert users alike, generative AI offers rapid benefits in a variety of data integration use cases. We will explore how these new capabilities can help you redefine your data stack, discuss the state of the art of generative AI, and give you an understanding of how to maximise its capabilities. We will also dive into SnapLogic's groundbreaking advancements in unlocking the full potential of generative AI with SnapGPT - the first generally-available integration solution to use generative AI and large language models to help you integrate and automate, faster than ever before.
Do You Remember The First Time? Tips and Tricks for a Successful Data Strategy from Scratch
In this session I will talk about how we have approached developing, articulating and agreeing the three-year Data Strategy at Evolution Funding that will enable us to unlock the true value of 15+ years of automotive retail data.
I will cover the steps we have taken, the challenges we have encountered, how we have continued to deliver value whilst developing it, and how we intend to measure our success over the coming years.
What can we learn from the World of Gaming
' Improved ability to plan and strategise, which can lead to better execution of projects and goals.
' Increased engagement and enjoyment in learning and training, which can lead to better retention and application of knowledge.
' Improved adaptability and flexibility in different situations
' Enhanced problem-solving and critical thinking skills can lead to better decision-making and problem-solving in real-life scenarios.
' Enhanced ability to manage and delegate tasks, which can lead to more effective management of teams and projects.
' Improved communication and negotiation abilities can lead to more successful business deals and interpersonal relationships.
' Opportunities for experimentation and learning from failure can lead to a more resilient and innovative mindset.
' Improved ability to handle uncertainty and ambiguity can lead to better handling of unexpected situations and the ability to find opportunities in difficult times.
Traditionally we have viewed the visualisation of data and storytelling as a 2-dimensional exercise. The development of virtual and immersive environments provides the opportunity to take visualisation and storytelling to a new level. Using virtual environments to teach data and digital skills makes learning and storytelling, immersive, engaging and fun.
My presentation will take us on a journey from virtual reality gaming to future-world problem-solving, storytelling and training.
Could Immersive virtual reality be the future of data visualisation, storytelling and literacy skills training?
The virtual reality world created in gaming environments, powered by AI and ML, shows us what the future will look like. By 2024, there are expected to be 3.32 billion gamers worldwide.
My presentation will explore why is this relevant to the Big Data London Audience
Immersive multiplayer gaming requires and enables the development of a number of skills that directly correlate to the real world,
' Development of digital literacy and technological skills, which can lead to better navigation and use of technology in various fields.
Data Security Governance in the Age of Generative AI
Virtually every organization struggles with Data Security and Governance due to the complexity of their data, organizational, and regulatory landscape. The introduction of Generative AI raises the stakes even more. Generative AI models can be a powerful insight and productivity tool if used properly, but they also open organizations up to unprecedented risk, so much so that many organizations ban the use of them with internal data. Now, not only does your data need to be secure and governed for internal and external data consumers, but your AI models and how your organization uses them also need to be secure and governed.
In this presentation, we will discuss unified data security governance and why it is now the starting point when it comes to Generative AI, strategies for successful data security governance programs. Using that as a starting point, we will address the importance and approaches to securing and governing the data AI models ingest and output, the models that data consumers can access, and the questions that users can ask.
Join Balaji Ganesan, Co-Founder, and CEO of Privacera as he shares:
"?	Strategies for automating and governing the data lifecycle with"
Unified Data Governance
"?	Removing bottlenecks and streamlining data security and access"
using a modern governed
"?	 data stewardship approach"
"?	How to extend your security and governance into generative AI"
From Pain to Gain: Maximizing Business Value with Data Observability
Bad data is the #1 pain for data teams'the unsolved problem of the Modern Data Stack. With this backdrop, Data Observability tooling is quickly becoming a necessity in every data team's tech stack. However, it's often treated as just another piece of technology. This is a shame, because Data Observability done right can be so much more. In fact, it is a key piece in unlocking large-scale business value from data.
In this talk, Patrik Liu Tran'CEO and Co-Founder of Validio' showcases concrete examples of how Validio's customers leverage Data Observability to ensure high data quality. They use Validio not just as a tool, but as an integral part of their business operations to maximize business value from data. He will cover success factors for winning with data quality, including tooling and ways-of-working.
Data Empowerment: A Hybrid Approach to Meeting Business Demands
Unleash the Power of Your Data: Embrace a Hybrid Solution for Future-Proof Data Management. In this session, we will delve into the evolving demands of real-time data and the challenges organizations face in extracting its true value. Join us as we explore key questions: Which use cases require real real-time data? How difficult is it to migrate your data to the cloud? Can you avoid vendor lock-in and ensure future scalability?
Adaptavist’s Self-Serve Data Culture: Powered by Matillion
How do you achieve a scalable self-serve data culture with Matillion and Snowflake? Join this session to learn how Adaptavist:
-	Built their Data as a Product solution (DaaP)."
-	Have implemented embedded analysts in teams across the organisation; favouring export of empowerment over import of domain knowledge"
-	Are enabling all their teams to trust and use data to make business decisions and deliver impact."
MLOps in financial services
Driven by data: How Porsche Handles Planning and Ordering using Data Products
To provide customers with an exceptional experience, it's indispensable to leverage data and AI-driven processes. For the Porsche AG, the goal is to provide the "Porsche Moment" - the unique sensation of starting the engine in your own customized Porsche vehicle. To achieve this, Porsche's IT and data teams collaborate closely to develop and implement specialized data products that support customer-driven innovation. These products include demand forecasting, intelligent planning and ordering, personalized configuration, and market prediction, all geared towards delivering excellence.
Products, not Demos: How ThoughtSpot and CWT Cracked the Power of GenAI to Accelerate Analytics Adoption
The challenge with Large Language Models is that it is very easy to build impressive demos of assistants. The hard part is building a product that actually delivers sustained value for customers and can handle the complexity of real life data models. Everyone has plans, a budget and some sort of a timeframe. However, very few (3% to 10%) actually use LLMs for production use cases.
This is where ThoughtSpot comes in.
We have the practical experience and one of the only production-ready implementations of GenAI in the industry drawing on early successes with renowned clients like CWT, presented by VP of Data Engineering and Architecture, Craig Haughan.
In this session, you will learn how we made that happen so that you know what to look for when assessing vendors or building the product in-house. We will share our revolutionary approach that empowers LLMs to thrive in real-world applications. From the infrastructure to customer success stories, learn how our solutions redefine the possibilities of LLMS.
Transformative AI: Beyond the ‘GenAI’ phenomenon
Discover the profound potential of AI that extends far beyond the buzz of 'GenAI' with this insightful session. We'll explore how the partnership between Dell and NVIDIA plays a pivotal role in propelling AI from hype to real-world transformation.
Delving into the analogy of an iceberg, we highlight GenAI as the visible tip and emphasize the crucial, often unseen, infrastructure beneath. Our focus shifts to the vital components shaping this foundation, such as Dell's tailored storage solutions accommodating AI's data demands, and NVIDIA's GPUs powering high-performance computations.
Through case studies, we spotlight the collaborative impact of Dell and NVIDIA across industries, showcasing AI's ability to revolutionize practices. Looking forward, we emphasize the importance of scalable solutions for future-proofing AI endeavors.
Join us to transcend the confines of GenAI and embrace the intricate reality of transformative AI. This session unveils how strategic partnerships and robust infrastructure harmonize to fuel AI's journey toward shaping a smarter world. Prepare to explore a nuanced perspective on AI's evolution that surpasses the hype and embraces the true essence of transformative AI.
Managing teams in the Age of AI.
Using Generative AI to summarise unstructured data
Making data easy at the worlds largest bank with HSBC and Collibra
Everyone starts their data journey with a different level of maturity, business drivers, objectives, and use cases. But irrespective of this, there are design and stakeholder management techniques that you can use to improve your chances of success. Join Gavin Brown from HSBC and Stijn Christiaens from Collibra to learn how HSBC started their data journey at the world's largest bank.
Composing Observable Decisions
Creating analytics, training and testing AI models is something we talk about a lot. This session will focus on what happens next.  Decisioning consists of the business rules, models and other analytics which may be constructed by multiple stakeholders in your organisation. Here, we consider how to compose processes which put those analytics to practice. We consider decision intelligence is both observing what is happening, being able to explain why it is happening and also testing the effect of changes to your process before they are operationalised.
Preventing data down-time:  data governance, observability & quality considerations
Data downtime is a significant challenge faced by organisations of all sizes and from all industries, resulting in lost revenue, missed opportunities, and reduced customer satisfaction. In this session, we'll explore how you can prevent data downtime by combining a business-first approach to data governance with data observability and data quality programs.
We will explore:
-	How to implement a data governance strategy that aligns with your organization's goals, priorities, and values, ensuring that your data is used effectively and efficiently."
-	Modern approaches to data quality, including the use of data observability techniques to diagnose data issues before they become significant problems."
-	How data governance initiatives, complemented by modern approaches to data quality and data observability, ensure data integrity and confidence in your decisions."
-	Critical Master Data domains that are impacted by data down-time."
ColorWise:The last inch (2.54 cm) of data analytics
Attendees will gain an understanding of how color impacts data interpretation and learn best practices for employing color effectively in their visualizations. By the end of the presentation, attendees will have the knowledge and skills necessary to become ColorWise data professionals, able to use color effectively to communicate their data-driven insights and tell compelling stories, especially in the crucial "last inch" of the data analytics process.
The IQ of AI: Measuring Intelligence in AI Models
Unless you've been living under a rock for the past 6 months, you won't have been able to avoid being bombarded with news about the latest developments in generative AI. Much of this information quickly devolved into wild speculation about the capabilities of these models, with many claiming that they are sophisticated enough to soon replace roles as diverse as writers, designers, lawyers, doctors ' and even data professionals. Others have gone further, claiming that these models are showing at least some signs of artificial general intelligence or that we're on an inevitable path to an AI apocalypse.
In this talk, we'll cut through the hype and delve deeply into claims of artificial general intelligence. We'll discuss how to more systematically measure intelligence in AI systems, and talk about where the current models stack up against this definition. By the end of this talk, you'll see how far away we are from creating truly intelligent models, and also see the potential of such an intelligence if it could be developed.
Git for Data: The Next DataOps Frontier
In the fast-paced world of data management, Git has been limited to code versioning. This presentation challenges that paradigm, showcasing how Git's operational principles can redefine the Developer Experience (DX), transform data deployment, and reinforce data governance policies.
We start by exploring how Git can reshape the DX. By integrating Git into your data operations, tasks such as version control, collaborative coding, and debugging become more streamlined and intuitive.
Next, we introduce Virtual Data Builds, a solution for managing both operational (environments, schema, data) and logical changes (code) through a familiar interface: Git. This method allows the creation of infinite virtual environments and instant deployments and rollbacks, enabled by the efficient reuse of data assets and avoidance of data duplications.
In closing, we'll spotlight Git's role in data governance. By consolidating policy management and enforcement under Git, we empower a robust, reliable, and trackable data governance infrastructure.
Data Mesh: Driving Continuous Executive buy in
It's a recessionary environment. Projects that directly boost the company's bottom line are often the only ones safe from being cut. Transformation programs like Data Mesh are tough to start and even tougher to sustain. In this talk, I will share practical advice on how to gain support and continuously keep the interest of high-level executives using 3 simple guidelines that will allow you to not only survive but also thrive !
How Bolt and OneFootball built trust in their customer data with RudderStack
Customer data is arguably the most important data a company has in its possession. An effective customer data strategy can yield deeper insights into customer behavior. Armed with these insights, business teams are better equipped to improve the customer experience and ultimately drive business value.
However, trust in data remains a bottleneck - if business teams do not trust the data in their cloud data warehouse or customer data platform, they are unlikely to leverage its full potential.
In this panel, we will discussing with data leaders from Bolt and OneFootball and will cover the the following topics:
Who should own the collection, cleaning, and modeling of customer data?
How can data teams build trust in data across the organization?
What infrastructure tools have been instrumental in delivering quality data across the organization?
How can data teams become the heroes in their organizations?
How can data teams collaborate seamlessly with their business partners?
Mind the gap: Finding the answer to the data & tech skills shortage.
Struggling to recruit data and tech talent? You're not alone.
Advancements in data and tech are driving economic growth, job creation and public service improvement. And the demand isn't slowing down' today, almost half of UK businesses are recruiting for roles that require data skills.
However, the shortage of data-literate talent challenges both businesses and society in leveraging the benefits of this new data economy. According to a recent government report 46% of UK businesses have struggled to recruit data roles in the last 2 years.
Gone are the days of traditional routes into these roles. Competition is fierce and companies need to look further than university students to meet their talent supply needs.
So, what's the solution? Join our expert panel to learn about:
'       Closing the data skills gap, a collaboration between educators, industry and policy makers
'       Inspiring the next generation, interventions to inspire school children
'       Fixing the talent pipeline and the major role employers have to play
'       Diversity & inclusion at the heart of the solution
And leave the session with concrete ideas on how you can be part of the solution.
DEVELOPING AIRFLOW DAGS IN ISOLATION WITH LAKEFS
As Apache Airflow establishes its stronghold as an essential tool for orchestrating complex data workflows, it is increasingly recognized for its critical role in data engineering ecosystems. However, if you're familiar with Airflow, you know that testing and debugging DAGs can be both intricate and cumbersome.
In this session, we will delve into how lakeFS, with its robust and scalable data versioning capabilities, can become a game changer when testing and debugging DAGs.
We will demonstrate how you can test your DAG in isolation on up-to-date production-scale data, all without disturbing the end user and consumer. lakeFS will also demonstrate how introducing schema or infrastructure changes becomes a non-issue when the power of version control is added to your data lake.
Join us as we demonstrate the capabilities and full potential of lakeFS to help you revolutionize your Airflow workflows.
Venturing Forward: The Mindset Advantage in Data Strategy
Every Company Needs to Own its GPT
As GenerativeAI takes the tech world by storm, it's critical for companies to take control of their data, algorithms, and models. Could this be the long-awaited breakthrough moment for Open Source Software?H2o.ai's mission is to democratise AI. As Generative AI takes the world by storm, H2o.ai Strives to make it accessible to everyone via releasing to the public h2oGPT, a truly open-source generative AI, giving organisations the power to create their own Large Language Models (LLMs) while maintaining their data integrity and H2O LLM Studio, a framework and no-code GUI designed for fine-tuning state-of-the-art LLMs. The current session will dive into the functionalities pertaining to these tools and how they can be used by companies to create their own GPT.
Morgan Stanley – Modern Data Replication in the Enterprise
Empowering Agility & Scale with Data Streaming: How Striim and Apache Kafka help CityFibre innovate faster than the competition
CityFibre's Adam Astle portrays CityFibre's recent and remarkable innovation journey. From facing challenges in limited reporting capabilities to harnessing the power of real-time data through innovative technologies like Striim and Kafka. Discover how CityFibre's shift to an event-driven-architecture transformed their operations, empowered developers, and paved the way for a data-driven future. CityFibre demonstrates how real-time data helps them innovate faster than the competition, and we gain valuable insight into CityFibre's exciting vision for the future.
How we use data to understand our customers better and develop greater customer empathy
Navigating the Open Hybrid Data Lake for Your Cloud Journey
Discover the world of the "Open Hybrid Data Lake". In today's data landscape, managing information across on-premises and cloud environments is vital. We delve into the complexities of this journey and emphasize the importance of retaining on-premises data for compliance and legacy system considerations. The hybrid data lake combines the best of the data lake, data warehouse, and data virtualization to enhance data access and break down silos. Starburst Galaxy adapts to secure your cloud journey's future, freeing customers from vendor lock-in, and optimzing for data access, data governance, security, and readiness for AI.
Bringing Kafka to the Edge and Back
Kafka has become a beloved project and protocol to get data between cloud systems but in this talk we discover how we can extend the edge like web, mobile, industrial IoT and robotics apps to send data to Kafka and ultimately your AI, ML and Big Data systems. We will also show use cases your business can build incredibly resilient but data rich products in the physical world while collecting information in the cloud such as Point of Sale systems for retail, management and maintenance systems for transportation, aviation and manufacturing as well as autonomous robots for the edge systems of the future.
Winning the Data Governance Game: Embracing an Infinite Mindset
Join Nicola Askham, The Data Governance Coach, for an engaging presentation to discover how the principles from Simon Sinek's "The Infinite Game" can revolutionise your approach to data governance. Learn why long-term success and adaptability are key, as we delve into the importance of transparency, collaboration, and an infinite mindset in building a resilient data governance framework. Gain practical insights and strategies to create a sustainable data governance practice that drives success in today's ever-evolving data landscape.
Apache DataSketches for Big Data Analysis
Many businesses face queries such as counting unique identifiers, finding frequent items, and understanding data distributions. However, these tasks are incredibly resource intensive at a large scale; particularly on streaming data or for real-time analytics. Given the rapid growth in dataset sizes, performing this type of analysis is now crucial to organisations of all sizes, rather than simply large enterprises.
We present Apache Software Foundation (ASF) DataSketches; a high-performance library for efficient large-scale data analysis. Using DataSketches, analysis can be performed orders of magnitudes faster than brute force. The sketches are extremely small compared to the original data and can be easily integrated into data cubes for efficient aggregate analysis. Our library is distributed in both Java and C++ and also has bindings to Python. It is compatible with Druid, Cloudera, Hive, Impala, PostgreSQL, Pinot, and Iceberg, in addition to being used by companies such as Yahoo. Our open-source library is free for any person or organisation to use.
We will introduce the audience to the notion of data sketching and detail the key wins they can expect by deploying these approaches. We will demonstrate how to use the sketches for OLAP-type queries using the Python API. Finally, we will showcase the key mergeability feature of our sketches. Using this feature we will show how to include sketches in data cubes so that aggregate statistics can easily be found over varying time periods. This is an example of a type of analysis for which a brute-force approach simply would not scale.
Everything that went wrong with our Data Strategy, and what we’re doing about it
Data Transformation is hard. Particularly at an organisation that's over 100 years old. In this talk i'll walk through our journey so far, sharing the lessons learned and what we're doing about it. We'll cover a mixture of Operating Models, People, Technology and Methodologies.
The Great Data Debate 2023
Don't miss this year's Great Data Debate at Big Data LDN where conference chairman and industry analyst Mike Ferguson will host executives from industry leading software vendors to discuss challenges, trends and success factors in implementing data and analytics.
Applications and misapplications of A.I. and NLP in text analytics: some lessons learned and recommendations.
Safeguarding Sensitive Data in the Age of Generative AI
In this session, I'll explore the privacy challenges encountered by companies leveraging generative AI. I'll unveil a pragmatic solution'a data privacy vault'to fortify the protection of sensitive information throughout the lifecycle of LLMs. I'll demonstrate how this approach bolsters privacy with a real-world sample application of a customer support chatbot powered by GPT.
Taking the data out of data culture
Navigating the ever-evolving landscape of Big Data, AI, ML, GenAI etc can be daunting. Staying informed about the latest industry buzzwords is a challenge, let alone harnessing their potential to create meaningful value. But the true value of data lies in its ability to solve real problems. Join Manca Vitorino and Women in Data' to explore how ICIS (part of RELX group) put curiosity, courage, passion and accountability at the heart of its data culture and data literacy journey to enable impactful problem-solving and drive business value.
The Future of AI and Analytics across the life sciences ecosystem: Generative AI for the use of good.
New technological advancements like Generative AI have huge potential to shape the future of drug discovery, development and innovation. But, how can we harness the power of this technology to gain a competitive advantage. In this fireside chat, Iain Brown, Head of Data Science from SAS and Neeraj, Head of Data, Analytics & AI from ViiV Healthcare (part of GSK) will discuss:
-	What is Generative AI and the importance in commercial and medical applications for pharmaceuticals"
-	How Generative AI can optimise clinical trials."
-	How to deliver effective Generative AI models using a fully integrated, open source, cloud-native AI and analytics platform."
-	How to overcome bias and ethical Considerations using Generative AI for pharmaceutical applications."
Enabling AI in an NHS Acute Trust with Plotly Dash
The Data Science team at Somerset NHS Foundation Trust specializes in predictive and prescriptive techniques to generate insight for improving patient care, staff welfare and identifying operational efficiencies. The team is on a mission to breakdown the barriers to AI and Data Science in the NHS by creating user designed tools that empower their colleagues across the Southwest of England. In this talk we explore how Plotly Dash enterprise was a critical component to unlocking the potential of AI in healthcare by exploring applications such as.
-	Live Emergency Department Monitoring"
-	Causal impact analysis for decision-making support"
-	Discrete Event Simulations of complex systems"
-	Geospatial planning of new or changing services"
Join Andy Mayne, Head of Data Science, AI, and Operational Research at the Somerset NHS Foundation Trust to learn more and see the organization's Python apps in action.
Child Labour Index: How is HACE using data and AI to leverage the power of investors and tackle the issue of child labour?
This talk addresses our approach to one of the world's biggest social issues - with 160 million children (on an upwards trend!) in child labour as of 2020. The vision to use technology and data to address child labour is ground-breaking. The use of technological innovation and vision has pushed HACE into global leaders on how to address data challenges in the 'S' of ESG, influencing the future of how we use data and technology to address supply chain visibility challenges.
HACE is launching the Child Labour Index; the only quantitative metric in the world for child labour performance at a company level. Our robust scoring methodology is based on cutting-edge AI technologies, combined with HACE's subject matter expertise, creating our own industry-leading AI within the Index. This disruptive approach to traditional ESG indexing and data approach is core to the product. This will provide the investor community quantitative leverage to push for stronger company performance on child labour.
Yin and Yang – How Deliverect secures data access at scale to become data driven
You have to become data driven, but when working with sensitive data you also have to keep your data secure. Companies that find this balance will be tomorrow's champions. In this session, Antonio Curado (Technical Lead Data at Deliverect) and Bart Vandekerckhove (Co-founder Raito) discuss Deliverect's journey to use data to support their ambitious growth strategy, and how they secure data access at scale to become data driven in a secure and private way.
Marketing Has A Data Problem, Not A Software Problem: Transforming Marketing through a Warehouse-First Approach
In today's data-driven world, data and marketing teams can no longer operate in silos and just rely on pulling from disparate third-party data sources. Join us as we unpack the emergence of the modern marketing data stack in response to platform and privacy challenges, its impact on data and marketing teams' go-to-market strategies, and ways to create a unified customer view to maximize your return on ad spend. We'll explore how Snowplow's enterprise-grade data collection and modeling combined with others in the modern marketing data stack provide superior analytics compared to legacy tools like Google Analytics.
Choosing the Right CDP: Tips for Tailoring Customer Data Platforms to Your Needs
Explore Customer Data Platforms (CDPs) from their fundamental principles to the evolution of batch CDPs and the shift towards real-time capabilities. Understand the various CDP types, each offering unique features and benefits. Delve into the advantages and disadvantages of real-time versus batch CDPs. Conclude with expert tips to help you choose the right CDP for your specific business needs, ensuring a seamless customer data management strategy.
Overcoming roadblocks, prioritising value and taking a modern approach to data products
How we use Power BI to make data led decisions on product development and customer engagement
Snowflake in the Data Marketplaces
Panel Debate:  How to make sure your Data Strategy keeps working for you
Panel: Data Governance Duel: Striking a Balance between Enterprise and Iterative Approaches
Join us for an engaging and thought-provoking panel debate that delves into the world of data governance, as we explore the merits and challenges of two distinct approaches: Enterprise Data Governance and Iterative Data Governance. This lively discussion will bring together industry experts to discuss the best strategies for effectively managing data assets in today's dynamic business landscape.
The discussion will explore questions such as:
-	Which governance model"
-	 offers better scalability and flexibility for businesses of different sizes"
and industries?
-	What are the cultural"
-	 and organizational changes required to successfully implement either approach?"
-	What are the potential"
-	 risks and pitfalls associated with each approach, and how can they be mitigated?"
Panel Debate: Similarities in temporal data across industries and organisations
The criticality of having the right data at the right time to make important business decisions is universal across industries, but do different industries require different skills to analyse their data or at the end of the day is data just 'data'? What does it take to be able to spot signals or anomalies in data and is it 'data specific'? Our four panellists come from four very different industries yet have similar needs for time driven data. They'll take a look at the similarities, and differences, in different types of data in their industries and the tools and skills required to leverage them.
Getting the most from your Modern Data Stack Investment
The talk will focus on the key elements of a Data Strategy that tend to be overlooked and lead to blockers in achieving a data driven culture AND a positive ROI on your MDS investment.
Data Fluency Training:
As part of any effective and well-thought out Data Strategy, it is vital to implement ongoing Data Fluency Training to decision makers who sit outside of the Data and Analytics Team. This is still something that has not got the traction it deserves and is one of the primary reasons why organisations fail to become data driven. The data and analytics team should not be a bottleneck for reporting or analysis.
Data Democratization Implementation:
In tandem with the Data Fluency Training, it is vitally important to implement an effective data democratization strategy. This is not easy and is often faced with roadblocks but again if a company is to get the most from their MDS investment, it is vital to democratize data outside of the data team. This obviously needs to be curated effectively and done in a secure and organized manner, but it is a critical step to move towards a data driven culture.
From POC to Mission Critical: How to build a Fast Data tooling strategy
Fast data enables organizations to extract greater value from the data flowing through their business.  It's now pivotal to remaining competitive in all major industries.
Despite this, many organizations fall into the trap of scaling fast data adoption without an underlying tooling strategy.  Built on the foundations of a POC that eventually lands in production, few think longer-term about the challenges you will meet along the way.
In this talk, we'll explore both technical and organizational challenges you will wrestle with as your fast data maturity grows to equip yourself to handle upcoming problems.
How Cereal Partners Worldwide Scaled Data-Driven Decisions with Augmented Analytics & Gen AI
Step inside the transformative journey of Cereal Partners Worldwide (CPW), a joint venture between industry giants General Mills & Nestl', as they redefine decision-making in the era of AI & Big Data. Hear how CPW modernized its analytics processes, turning to augmented analytics and generative AI to realize their vision for a data-driven culture. We'll share challenges faced, strategies implemented, and the tangible results achieved in this ongoing journey towards democratized analytics.
Data Office Dynamics: Navigating the Modern Data Frontier in Consumer Industries
The role of the data office has become even more complex with the need to deliver value as well as manage the expectations and excitement generated by new trends and accelerating opportunities. Our expert panel of data leaders will bring their experience and real world examples to this high energy session as they explore how to navigate this increasing complex journey. They will articulate what it means to be a data leader in the Consumer Industries and how to measure value when we're talking 'fixing the basics' vs the 'sexy stuff'.
Join this session to learn what leading an organisation's data means in today's fast changing world and leave with positive tips to apply in your own environment.
Building a Generative AI App on Private Enterprise Data with Retrieval Augmented Generation (RAG)
Large Language Models (LLMs) are typically trained on a large collection of publicly available data with an expiration date. Unfortunately this means LLMs are unable to recall any data outside their repository, making them overall less effective for domain-specific tasks.
Retrieval Augmented Generation (RAG) is a technique designed to recall data from outside a foundational LLM, enhancing queries by introducing relevant, semantic data into the context of the original query.
In this session led by SingleStore CMO Madhukar Kumar, you'll get an immersive, hands-on look at how to build a generative AI application on your private enterprise data with RAG using SingleStoreDB.
The session will cover:
-	How to introduce RAG into your foundational LLM"
-	Real-world use cases where RAG can be incorporated into generative AI applications"
-	How SingleStoreDB leverages RAG as a more cost-effective option to pre-training and fine-tuning LLMs, reducing hallucinations"
Panel Debate: Why every organisation needs to implement data contracts and how to get started
Join Maarten Masschelein as he hosts a panel discussion on why every organisation needs to implement data contracts with Andrew Jones (Creator and Author of Data Contracts) and Max Schultze (Associate Director of Data Engineering, HelloFresh).
Focusing on the What, the Why, the Who, and the How, of data contracts, these data practitioners will bring to life both the theory and the practice of data contracts. Attendees will discover how data contracts are a force for good for any organisation that is building a domain-oriented, decentralised data platform, and how to drive data culture change with data contracts; and how to design and how to implement a data architecture based on data contracts.
It promises to be lively, informative, and packed with actionable insights on bringing data consumers and producers together, whilst increasing accountability and ownership to deliver data that everyone can trust and use.
LexisCreate and prompt engineering
Creating a vibrant and thriving Data Community. For Now and Beyond.
Discover the essence of building resilient data communities in our panel session with key figures from Zoopla, IG Group and Long Harbour. Explore the strategies used to establish, nurture, and adapt their data communities, ensuring they remain agile and impactful in an ever evolving data landscape. Join us to shape a data driven future.
Panel Debate: Gen AI – Separating Hype from Reality
Book Launch Event: DataOps.live Data Products Done Right Reception
Literature, Libations and Luminaries (oh my!)
Join DataOps.live and sponsors AWS, Hakkoda, Coalesce, DQ Labs, and Kubrick Group in the Y-Axis Keynote Theatre on Wednesday, Sept. 20 from 6-8pm for the launch of our Data Products for Dummies book.
Pop in for some appetizers and libations and mingle with our book authors and special guests - a literal who's who of data products: Paul Rankin, Head of Data Management Platforms, Roche Diagnostics; Ravit Jain, Founder and Host of 'The Ravit Show'; Christian Tabb, Co-Founder and CCO, LEIT Data; Victor Filipescu, Data Architecture Senior Director, NTT Data UK; Stijn (Stan) Christiaens, Co-Founder and Chief Data Citizen, Collibra; Toby Pearson, UK Lead Partner and Head of Group Data, Projective Group, among others.
The highlight of the evening is the book signing itself, which serves as a platform for networking and forging new connections. Meet with our authors ' Sanjeev Mohan, Principal SanjMo and former Gartner analyst; Guy Adams, Co-Founder and CTO at DataOps.live and Snowflake Superhero; and Justin Mullen, Co-Founder and CEO at DataOps.live.
Join us to celebrate the launch of this highly anticipated book, and to exchange ideas, inspirations, and anecdotes. We will be giving out books to all attendees, and our authors are happy to autograph copies.
Apache Kafka Meetup: Exploring Fast Data with Kafka – Moving from Batch to Real-Time
Meetup: Data Governance Knowhow London
Please pop down to the Data Governance theatre from 6pm on Wednesday to catch up with the community over drinks and nibbles!
Meetup: Data Mesh Learning
If you're on your data mesh journey or just getting started, we invite you to join the Data Mesh Learning community for a couple talks and networking in the Data Mesh Theater. Pizza and beer will be provided.
Meetup: Databricks
Meetup: Sip, slice, and strategize: Explore data to outcome applications over beer and pizza
Today, a lot of organizations are grappling with what you could call a "data-rich outcome-poor" situation. The sheer volume and complexity often end up taking the spotlight away from what really matters ' achieving results.
This session isn't just about discussing challenges; it's about charting a course to solutions with some good old beer, and delicious pizza. We'll dive into how some of the big enterprises are actually getting things done faster.
You'll also get a sneak peek into Gathr - the world's first data-to-outcome platform:
' How Gathr breaks silos, enabling teams to collaborate seamlessly, experiment freely, and innovate rapidly.
' Discover how organizations can leverage machine learning within their data pipelines and applications, utilizing Gathr's out-of-the-box capabilities.
' Break your teams free from the convoluted cycle of adopting entire product suites and product-per-solution procurement cycles
So, if you're up for some insights, a bit of networking, and a whole lot of learning, why not join us? Let's decode the data to outcome challenge together, all while enjoying a chilled brew and some mouthwatering pizza. Cheers! ????
Meetup: Simplicity by Design: Dell & Cloudera host drinks, discussion and canapes
Meetup: Heroes of Data – Generative AI for Data Engineering practitioners—cutting through the hype
Welcome to Data Engineering Meetup #9 by Heroes of Data, hosted by Validio and Big Data London!
The Nordic meetup series is coming to London with a splash, and we hope to meet you there. We will be discussing the hottest topic in data: Generative AI' from a practical perspective that cuts through the hype.
We will be hosting some of the greatest thinkers in GenAI:
Victor Jansson, Manager, Solutions Architecture at AWS & serial startup CTO
Patrik Liu Tran, PhD, Co-Founder & CEO of Validio, a Deep Data Observability Startup
Topics will range from how to practically leverage GenAI in data engineering, to the best architectures for hosting and using LLMs, to new business models and ways of thinking that are enabled by GenAI.
Stay tuned as we announce additional speakers over the coming days.
Meetup: The High- Performance data debate
The debate will be facilitated by 4 key spokespersons and influencers in the data field.
Matt Housley who will lead Data Ingest and data quality ; this will be followed by Nick White who will lead Data Pipelines and Data security; followed by Joe Reis who will lead The future of Data modelling and the impact of Generative AI, the final topic will be hosted by Chris Tabb and will cover the measurement of Business value .
This will be followed by a town hall session for the floor
Other Key influencers participating in the debate are Andrew Jones , Serge Gershkovich, Scott Taylor and Svetlana Tarnagurskaja
Meetup: Lots of traction for the Trino SQL query engine
The Trino query engine and the ecosystem of supported data sources, clients, integrations, and add-ons is growing by leaps and bounds. In this session we will briefly discuss the history of Trino starting under the name Presto at Facebook over 11 years ago.
We will then dive deeper into recent innovations such as fault-tolerant query processing and support for modern SQL statements such as MATCH_RECOGNIZE, MERGE, json_path and table functions. These improvements and the long history of Trino with supporting multiple table formats and many other data sources make Trino ideal for lakehouse creation, migration and operation, and we will talk about some specific table procedures, performance improvements, and other updates for related use cases.
You will learn about the expanded focus of the community around Trino to support Python-based workflows with trino-python-client, dbt, Ibis, and the rich ecosystem of tools available to query and process large data sets with Trino for analytics and other workloads. Finally we discuss updates and metrics about the project and community, and provide a look at the future of upcoming improvements.
People, Process, and Platform – Is Generative AI creating a Game of Thrones and how can we lead our organisations on the AI revolution?
Join some of the biggest data powerhouses in the industry as we discuss the evolution of data culture resulting from the GenAI movement. The panellists will discuss the implications of generative AI on various aspects of organisations, including workforce dynamics, decision-making processes, and the role of human creativity. They will explore how generative AI can disrupt traditional organisational structures and challenge existing power hierarchies. Additionally, the panel aims to provide insights and share strategies for leading organisations through this transformative period, including the importance of fostering a culture of innovation, up-skilling employees to work alongside AI systems, and establishing ethical guidelines for AI usage.
Introducing Microsoft Fabric: Data analytics for the era of AI
Data is the fuel for AI, but how can you make the most of your data and analytics in the era of AI? Join Mohammad Ali, Group Product Manager at Microsoft to learn how Microsoft Fabric, the new AI-powered analytics platform, can help unify, manage, and empower your data across your organization.
Breaking Batch: Data Streaming and the Modern Data Landscape
To meet the demands of their modernization and digitization initiatives, many enterprises have evolved and implemented their data architectures in an ad-hoc way, alongside legacy approaches, with no rigor or governance. Traditional data pipelines built on point to point, brittle and batch based connections became problematic, impacting the operational/analytical divide. Real-time data streaming has emerged as a powerful alternative, enabling your data-dependent systems to continuously act upon, and react to the most up-to-date enriched data sets. After all, life doesn't happen in batch. Join us to discover the core principles of the modern data flow, explore some of the current use cases we see taking advantage of the shift to treating data as a real-time product using Confluent, before taking a look at the future of these tools in a real-time world.
Data to Story: Solving the Blank Canvas Problem Using Infer and SQL-inf
The 'Blank Canvas Problem' represents the initial stumbling block analysts face with an abundance of raw data and the uncertainty of crafting an insightful story. This talk presents a pragmatic solution with Infer, a revolutionary platform that incorporates SQL-inf, an ML-enhanced SQL variant. SQL-inf operates seamlessly with all data warehouses and integrates effortlessly into existing workflows without any alterations, making it highly versatile. With concise commands like PREDICT, EXPLAIN, and FORECAST, Infer generates automated visualizations alongside data-driven insights curated by large language models. This approach swiftly populates the blank canvas with a meaningful data narrative, which analysts can then refine and tailor. Furthermore, Infer's scheduling feature ensures that these stories stay relevant and updated with new data as frequently as desired. Discover how Infer and SQL-inf equip analysts to conquer the Blank Canvas Problem, augmenting efficiency and unlocking powerful storytelling potential across diverse datasets. Through the marriage of adaptability and automation, analysts are empowered to transform data into dynamic, evolving stories with ease and precision.
Methods & Frameworks for a value-driven and ethical Data & Analytics strategy
All organizations want to deliver value from their Data & Analytics investments, but 92% struggle with organizational and human challenges. Defining & demonstrating value is a key subject to drive the transformation, align efforts and develop the culture to enable adoption.
In this session we will share very concrete & pragmatic approaches, methods and frameworks to estimate, track, and demonstrate value, risks and costs for your Data & Analytics investments : depending on your maturity, on your organization structure, and on the lifecycle of your initiatives and data & analytics products
Learn how to become "value-driven"
The perfect couple: Uniting Large Language Models and Knowledge Graphs for Enhanced Knowledge Representation
Large Language models are amazing but are also black-box models that often fail to capture and accurately represent factual knowledge. Knowledge graphs, by contrast, are structural knowledge models that explicitly represent knowledge and, indeed, allow us to detect implicit relationships. In this talk we will demonstrate how LLMs can be improved by Knowledge Graphs, and how LLM's can augment Knowledge Graphs. A perfect couple!
How EDF is Boosting Productivity with Matillion
As the demand for data accelerates, enterprises face the challenge of increasing the productivity of their data teams while working with limited resources and coding skills. In this session, you'll learn how Matillion makes data work more productive for EDF by empowering the entire data team ' coders and non-coders alike ' on a single platform to move, transform, and orchestrate data pipelines, faster. By leveraging Matillion and hosting their data assets on Snowflake, EDF experienced tangible benefits like enabling critical downstream processes, driving successful data science and analysis initiatives, and providing self-serve capabilities to support their code-flexible team. Discover how this collaboration is driving real-world results and propelling EDF into a data-driven future!
Empowering Excellence: Nurturing a Learning culture within Data Teams
In this insightful panel discussion, attendees will have the opportunity to learn data leaders on sustaining a learning culture within data teams. They will gain valuable insights into addressing the challenges posed by constantly evolving skill requirements and building a positive employee experience in a post-COVID world. The discussion will provide actionable strategies for continuous learning, upskilling, and reskilling data professionals, empowering them to stay innovative and adaptable. Additionally, attendees will discover practical approaches to foster a cohesive and supportive team environment, promoting employee morale, productivity, retention; and the crucial role of leadership in fostering curiosity, collaboration, and skill development.
Overall, this panel promises to equip participants with the knowledge and tools to nurture a dynamic learning culture, enabling their data teams to thrive and drive success in an ever-changing data-driven landscape.
Cloud migration with Snowflake and DataOps.live – setting yourself up for success
Migrating from a traditional on-premise approach to a cloud solution like Snowflake can deliver huge value, but actually getting this right on the first try can be fraught with complexities and issues.  Similarly, if you migrate to the cloud, but keep all of your legacy ways of working, you are missing the point! Join us as we take you through how we used DataOps.live to migrate our older projects over to Snowflake and improved both our agility and governance in the process. Learn how this set a solid, practical foundation for all future projects that need to follow the same path.
In this session you'll learn:
-              Ways to approach a cloud migration that will help set you up for success
-              What are the issues to anticipate and avoid in a cloud migration
-              What are some best practices you can adopt along the way
-              How you can take lessons learned and iterate on those for success
Building a Data Foundation that you can Trust
AI/BI for Self Service – How AI removes friction for data consumers, analysts and developers.
Scoring Goals with Data: The Playbook for Securing Funding & Success
Winning hearts and minds to secure funding for data capabilities rarely starts with Data Governance at the core. If you really want to score those goals, it starts with the Why. Why Data Culture should be at the centre of your strategy, Why data is a key enabler to your business objectives and Why that data should be treated as an asset. Data Governance is the foundational layer, but the potential it unlocks is the sweet spot to winning that penalty shoot out.
In this informal fireside chat, Helen and Lou, will draw on their experience from CDO roles and leading large scale data led functions to give you the foundations for building a compelling case for data management and securing the funding you need. You'll takeaway how to craft stories that resonate with your leadership team, how to frame the benefits & frame the risks of doing nothing, and why you need a positive and open attitude to build trust and be successful.
Navigating Cloud Transformation and Data Mesh Synergies – Insights from Raiffeisen Bank International and Hitachi Vantara
Key Takeaways
Join transformation leaders from Hitachi Vantara and Raiffeisen Bank International (RBI) to navigate the Complex Cloud Transformation and Data Mesh landscape. This session goes beyond traditional cloud transformation to explore the groundbreaking Data Mesh paradigm, illustrating its role in enhancing agility and governance in RBI's digital odyssey.
-	Incorporating Data Mesh: Grasp how Data Mesh complements RBI's cloud strategy to foster data decentralization, scalability, and business-centric data ownership."
-	Strategic Focus: Learn why agility and velocity take center stage over cost in cloud transformation in partnership with Hitachi Vantara."
-	Unique Challenges: Uncover any company's hurdles, such as organizational complexity, technical debt, or scarce cloud talent."
-	Robust Governance: Learn about emphasizing a solid governance framework that facilitates a cloud-centric corporate culture."
-	Human Element: Understand the critical role of training and workforce transformation in the success of cloud initiatives."
-	Actionable Lessons: Walk away with practical insights for defining goals, implementing governance, selecting cloud providers, and calibrating ambition based on RBI's real-world experience."
Why Attend: Gain a practical roadmap from our experience to navigate your cloud transformation and data management challenges. Whether you are an IT leader, cloud strategist, or interested in change management, this session will equip you with actionable strategies and real-world examples.
Join us for an engaging conversation that not only demystifies cloud transformation complexities but also illuminates the transformative power of Data Mesh in the modern data-centric business landscape.
Data Science: Building localised products within a global organisation
How LexisNexis leverage a global organisation of data scientists and data science capabilities to build localised products that customers love
Nurturing a people-centric culture to enable data-driven value
How can you effectively transform the data and technology culture in an organisation while balancing innovation and control? In this session, we'll uncover the challenges Convex faced and its approach to Smart Data Democratisation with Dataiku.??
Adapting to Shifting Consumer Expectations and Privacy Regulations: Strategies for Data Governance and Transparency
Join this session to explore evolving consumer trends, and explore viable approaches to providing transparency in the digital landscape. Understand how companies are adapting to shifting consumer expectations and preferences, from hyper-personalization to more cautious behavior. Discover strategies for navigating the gray areas and continuously changing regulations, and learn about the pivotal role of technology in reshaping data governance and business models.
Discover Data Management: Unplugged
This is the first of its kind session! Discover how to win and strive and be successful in the Data Management space! This is the first and only data management unplugged session!
A 30 mins unplugged session where you can ask your data management questions and I will endeavour to answer them.
If you've challenges such as team, culture, design, deliverable, ways of working, value propositions etc. Come to this session with your questions and get the answers to them.
I want to connect with you and help you to grow, strive and win in your data management journey.
This session is for you, if you're any of these:
"	Want to start your Data Management career or journey?"
"	New to Data Management?"
"	Practitioner struggling to deliver Data Management successfully?"
"	Want to know how to successfully deliver Data Management?"
Accelerating data-driven workflows for semiconductor design, verification and implementation
Why Data Quality and why it’s Never too Late?
Why this topic:  We are living in a data driven world. More and more organisations are focusing on building data driven organisation but I fear we are moving away from the basic i.e need to have a quality data. It's important we ensure we focus on the quality of data before we look any further.
Who will be interested in this topic: Data Governance specialists, Data Quality analysts, Data Culture enthusiasts, Students looking to pursue a career in data
What would the webinar cover?
"?	Why Data Quality?"
"?	Who is responsible to ensure we capture & maintain quality data?"
"?	What is the true cost of poor data quality and its impact?"
"?	Are we thinking long term? Are we practising sustainability?"
"?	Why Data Culture is not another buzz word and how you can make a difference in your role?"
Unleashing the True Potential of Data as a Product: Empowering Collaboration and Innovation with an Intuitive Data Platform
In this session, we will explore how to unlock the full potential of Data Mesh by seamlessly transforming raw data into valuable finished products through a disruptive and user-friendly data platform.  By fostering efficient collaboration between business domains and technical users, we will explore how this approach revolutionizes data utilization.  Emphasizing collaborative governance (Data Self Service) and unwavering data protection (Global Policies), we will uncover how this framework empowers users without compromising on data security.
During our discussion, we will showcase the power of the Denodo Platform in embracing today's distributed data ecosystem. Through end-to-end implementation of logical approaches powered by AI and NLP, we will challenge traditional monolithic architectures, ushering in a new era of innovation and data-driven decision-making and propelling organisations into the future of the data mesh approach.
Executing on Data
How are clients using these features that did not exist before, how do they realize value and support mass-distribution of data? How do they manage data drift? It's not teatime with Data Governance Best Practices anymore, it's time to let go of the throttle and set data into overdrive.
Real-time analytics that delivers split-second response times for AA Insurance
Insurance comparison websites in the UK give top billing to insurers who respond fastest to online requests for quotes. The AA, the leading provider of roadside assistance services in the UK, needed a solution that would enable it to underwrite a prospective driver and deliver a risk-balanced, competitive insurance quote with sub-second speed. They also needed split-second response time to move the AA to the top of customers' lists on comparison website for people searching for an insurer.
Discover how the AA use the Actian Data Platform can now:
-	analyze hybrid data sources to provide real-time insurance quotes as well as provide executives with performance insights on the AA's insurance business"
-	routinely earn a top position on comparative insurance sites"
-	analyze applicant-supplied data, review data from public sources and deliver risk-balanced competitive insurance quotes within fractions of a second."
Lakehouse Transition – Rapid Data Access and Insights
The current day of data requires high data integrity, high data quality, fast iterations and accessibility across users.
-	How to move from shared compute/storage loads to decoupled"
storage/compute with lakehouse architecture.
"o	Multiple computes including trino Galaxy."
-	How to maintain high data quality and integrity across"
squads/business users.
"o	Proactive testing via DBT trino Galaxy."
-	Providing high user accessibility."
"o	Combine all storage layers and make them queryable via trino Galaxy."
Planet Governance: The Natural History of Getting Data Governance Done
Why is data governance so difficult? On the governance journey, we face internal obstacles like bias, uncertainty, and social pressures. How can data leaders channel natural instincts... to support data governance, rather than obstruct it?Join industry experts Nicola Askham, The Data Governance Coach, and Julie Smith, Director of D&A at Alation. The two will share lessons learnt to help you craft a data governance plan that puts people first. Come for an informative, enjoyable, interactive session. And leave with tips and tricks to make YOUR data governance initiatives successful!
From Migration to Adoption: Community Fibre’s Data Journey with a Unified Platform
' Tips for adoption and driving a strong data culture
Join Kishor Toshniwal , Chief of Architecture at Community Fibre, discuss the journey consolidating systems, migrating to an end-to-end data analytics platform, and driving adoption across the entire organization. Discover how to increase value and adoption of the tools that you have, and get a glimpse of what the future holds for a modern analytics infrastructure.
Here's what you can expect from this session:
' How to make pragmatic architectural decisions
' Serving out information in a governed and secure manner
Maximising Database Tech: Leveraging Moore’s Law for Sustainability
Investing in efficient technologies is a proven method for driving innovation and reducing costs. Beyond cost savings, recent research demonstrates that adopting such technologies contributes to reducing CO2 emissions. The magnitude of these savings can exceed what can be achieved by planting 10s of hectares of trees. As the European Union's Corporate Sustainability Reporting Directive (CSRD) comes into force, coupled with the current economic climate, a growing number of companies are now considering adopting efficient databases such as Aerospike.
CTRL+C, CTRL+V: From copy and paste, to tailored data strategy and leadership
Whilst there is a lot to be gained from previous experiences and other people's strategies and actions, success is predicated on your data strategy being specific to the context of your business.
Just as every company has its own distinct identity and goals, their data strategy requires a tailored approach to align with their unique attributes, culture and strategy.
During this talk, Jason will talk through the need for a crafted data strategy. Drawing from experience of working with 100's of organisations, he will share how you best understand the context of an organisation and the elements that make them unique, how you align your data strategy to that and how to adapt as your organisation adapts.
Using data effectively has become central to business success. Given the pace of change and the pressure to deliver, it might seem enticing to emulate the data strategies of others by copying and pasting what brought them success, or to simply 'rinse and repeat' what you have done elsewhere.
Creating business value with a data fabric strategy
Navigating AI Governance in the Age of Third-Party Models
AI Governance and the question of how best to effectively develop, deploy and monitor models at scale is itself a maturing field. What happens when we add third party models to the mix which promise great value, but also present great risks? How should we adapt our AI Governance processes to safely leverage a new suite of models that we have not trained or deployed, and how will it shape the risk and regulatory landscape for AI?
Architecting a Cloud Data Mesh with database and event change streams for real time Gen AI applications
Unlocking Revenue Growth: Automation for Data-Led Selling Delivering Tangible Results
Join us for an expert session with Emma McQuillan, where we'll delve into how OUP is using cutting-edge data and customer insights to support services to customers all over the globe. Get ready to learn about OUP's data-led selling approach, which harnesses the power of automation and digital data sources to generate opportunities, track campaign effectiveness, achieve tangible results and boost revenue.
Emma will also share insights on how OUP is fostering a culture of analytics and upskilling their team, so you can take away practical tips for your own organisation.
Using AI and Machine Learning to Create Value in Insurance
How we help insurers create value for their customers, partners, and stakeholders. AI and ML can enable insurers to improve their products and services, enhance their customer experience, reduce their costs and risks, and increase their profitability. We also explore some of the challenges and opportunities that AI and ML present for insurers.
How ICAEW and GenAI can take membership CX to the next level
A business, technology and transformation view on how we introduced GenAI to a major professional membership body, to improve the internal and external customer experience.
'             The journey from idea to production-ready
'             The impact and change required to bring Gen AI into the organisation as a capability
'             Get a feel for the timeline and team to implement the solution
'             Key drivers that swayed decision making
'             Get a high-level peek behind the scenes of how the solution is constructed
'             Why new technology and customer experience are highly valued in ICEAW
From Insights to Impact: Harnessing Diversity in Data & AI
Join us for a thought-provoking and practical panel discussion that explores the symbiotic relationship between diversity, inclusion, AI and data strategy.
Our panel of industry trailblazers and thought leaders will discuss how inclusion and diversity manifest in the everyday landscape of data work, and the risks and impacts organisations face when they are not at the fore of data decisions. We will share practical examples of intentional action taken to integrate diversity and inclusion into data strategies which have yielded remarkable outcomes for teams for you to take back to your own organisations .
Powering the Future: The Role of Data and Technology in National EV Charging Infrastructure
Talking about the rapid adoption of electric vehicles (EVs) and the need for a robust charging infrastructure to support it. Thinking about hundreds of thousands of charge points by 2030, each producing data every second on the charge point status it's connectivity and user activity. How to utilise this data to overcome the challenges the EV driver experience, addressing uptime, availability, and reliability.
In future the sector will embrace the smart energy and real-time interactions. In the talk, I'll cover harnessing the power within this data to improve quality, uptime, security for the business and users and the tool sets which are best to manage the task including spatial and time-series analysis.
Instilling data confidence across your workforce
4. Assessing confidence across your workforce and why it's important to understand how confident your workforce is
2. Why data confidence should matter to an organisation
3. Approaches I have taken previously and experiences from building data confidence
1. What is meant by data literacy
Implementing Privacy by Design and By Default Controls in AI and Big Data Solutions.
Privacy by Design is a concept developed in the '90s by Ann Cavoukian, PhD, a former Information & Privacy Commissioner in Canada, that ensures that privacy becomes an organization's default mode of operation. All new privacy laws are adopting this concept ' Article 25 in EU & UK GDPR, Proposition 24 in California's CCPA, Brazil's LGPD ' and as a new ISO standard was launched this year ' ISO 31700-1:2023, Privacy by Design. In this session we will explore key requirements for privacy by-design and by-default, what specific controls need to be implemented in AI-based solutions, by software vendors and by customers and how to manage compliance with both the new ISO standard as well as all new privacy laws throughout the world.
Simplify complex data transformations in the Snowflake Data Cloud
Creating complex data transformations can be time-consuming and error-prone, resulting in delayed data delivery. There's no room for slowed-down data and analytics projects in today's competitive environment.
We will look at how StreamSets enables data engineers, data analysts, and business users to quickly and easily build data transformations in the Snowflake Data Cloud by using a no-code UI to eliminate tedious SQL coding and describe best practices, including leveraging pre-built processors, automating data drift detection and handling, and improving visibility and control across all transformation jobs.
Join us to discover how you can simplify complex data transformations in Snowflake using StreamSets Transformer for Snowflake.
Stream On: Transition from Batch to Streaming Data in Minutes
Join us as we explore how companies can leverage a holistically managed solution to move from batch processing to streaming data within minutes.
In this data-rich era, under a minute to real-time processing is required for business and operational relevance. Smart production lines, efficient supply chain management, fraud detection, and so many other use cases are beyond the capabilities of current solutions.
Despite a variety of open-source options and numerous solutions for dealing with real-time data, the market lacks a competitively-priced holistically managed solution to tackle the ever-changing data landscape. To accelerate development and minimize overhead, users need a solution that unifies ingestion and processing capabilities.
Move beyond the paradigm of data as a code input by empowering the swift building, deploying, and monitoring of the contextual data pipelines businesses need to strike back.
Navigating the need for data connectivity with the requirements of data governance and privacy
In this presentation, Progress DataDirect will discuss the release of its annual data connectivity survey. Highlights include  market attitudes towards data connectivity, privacy, and analytics' as well as case studies as to how leading organizations successfully navigate these challenges.
The Next Big Crisis For Data Teams
The only thing anyone can talk about these days is generative AI, but how can we get past fancy Twitter (sorry, X) demos and actually realize value with this groundbreaking technology? Faced with the 'AI crisis,' data leaders are tasked with capitalizing on this technology to drive impact for the business, but it's clear we have a long way to go. In this talk, Barr Moses, CEO and co-founder of Monte Carlo, will highlight what it takes to build more reliable data and AI systems - and avoid this impending crisis.
Multidisciplinary teaming to navigate the personalisation paradox: Balancing data privacy and marketing relevance
The digital revolution has changed the rules of customer engagement and brands need to navigate complex data ecosystems and privacy regulations in order to drive personalised customer experiences. To succeed, organisations need a culture of collaboration that brings together multidisciplinary teams: data privacy specialists, data scientists and marketeers.
-	How to balance marketing performance and customer identity protection"
-	The importance of continuous learning, and the impact of new technology on privacy"
-	The multidisciplinary team necessary to successfully navigate the personalisation paradox"
Join our interactive session delivered by Acxiom's leading experts in ethical use of data and the privacy landscape: Dr. Sachiko Scheuing, European Privacy Officer and Women LEAD Co-Chair; and David Keens, VP of Product EMEA and STEM Ambassador.
Learn about:
-	A summary of the UK and European data privacy landscape today"
-	Data science techniques to successfully protect individuals' personal identifiable information through cohort and anonymized data"
Event-Driven Architecture Transformation: Unleashing the Power of Real-time Agility & Data in Motion
NatWest is one of the UK's largest retail banks with 7m+ personal and 850k business customers.  All of whom expect to be able to check their bank balance at any time, to confirm transactions or to move money instantaneously.  Peter Pugh-Jones, Director Financial Services at Confluent, delves into the complexities of making this happen with Jia-Yan Gu, NatWest Principal Engineer and Yann le Rouzic, NatWest Streaming Platform Lead, and discovers how their event-driven architecture and data in motion transformation has enhanced customer experience.  Hear about how Confluent has enabled NatWest to optimise costs, increase productivity within data teams, and through chaos engineering, ensures a resilient and efficient platform.
A journey to one version of the truth
Vita Health Group is a private healthcare provider offering physiotherapy and mental health services. As a result of COVID-19, most of the workforce became remote, resulting in communication breakdown, increased silos, lack of transparency, data handling by nontechnical service managers, changes in the logic of the measures that are invisible to the employees, and a long period of time for producing key performance indicator reports without investigating why these changes are occurring. Moreover, the data were obtained from a third-party supplier, who handled our data and we had limited knowledge of how the reports were compiled. This situation spiralled into multiple versions of the truth across the services, frustration and lack of trust in data. It is therefore apparent that outdated, manual, and limited indicator reporting was no longer appropriate.
A substantial amount of work was required in order to track individual service performance and generate real-time insights with minimal effort. During the first phase, over 13 sessions were conducted to gather business requirements. This was then translated into phases, with Phase 1 being easy to build, Phase 2 medium build and Phase 3 difficult to build. We aimed to complete a total of 70% of the measures overall. Development of the work was overseen by the BI department and myself, BI performed rebuilding of the SQL tables, and the measures, I overseen communication, customer engagement, delivery, presentation of the dashboard.
Once the Phase 1 was complete, I had established a governance process which required approvals and an understanding of what and why was being modified. This has ensured that we are transparent in any changes to the business metrics, while also aware of the work that needs to be done. The project has laid strong foundations, improved trust, and provided a single source of truth for senior business leaders, allowing them to gain confidence in the results from one location and one version.
Mastering Data Management for Powerful Organizational Insights
: In the digital age, data has emerged as the linchpin of organizational success, serving as the driving force behind informed decision-making, accurate analysis, and predictive insights. As organizations navigate the complex landscape of data, the art of effective data management becomes a critical skillset to unlock the true potential of information.
This presentation dives deep into the essential principles that underpin a successful data management strategy, guiding organizations on a transformative journey from raw data to powerful insights. The journey encompasses a series of key principles that collectively pave the way for excellence in data management. This presentation equips participants with the tools to navigate the complexities of data management, paving the way for powerful insights and sustained success in the data-driven landscape.
Banking on Data Products: How Santander Delivers Clean, Accurate, and Trustworthy Data
Clean, accurate, and trustworthy data is essential for providing exceptional customer experiences at every touchpoint. However, many businesses struggle with the quality of their data, which hinders their ability to provide personalized experiences and seize new revenue opportunities.
Join Claire May, UK Head of Business & Change Management, and James Pitchforth, Head of Data Management, Corporate and Commercial Banking at Santander for an insightful discussion on how Santander is implementing a business model focused on delivering seamless experiences to achieve customer loyalty, hosted by Suki Dhuphar, Head of International at Tamr.
Santander, a renowned multinational financial services company, is effectively tackling this challenge. The company is developing a unified, accurate, and enriched view of its customers using Tamr's cutting-edge AI/ML technology. As a result, they are excelling at providing customized experiences across their extensive branch network and digital and telephone channels.
Making learning new research topics easier: Retrieval augmented generation (RAG) and Scopus vector search
Scopus AI aims to enhance the exploration of various subject areas and research insights, ultimately democratising knowledge for researchers and academics.
This unique combination enables researchers to delve into new topic areas in an evidence-based manner, expediting their journey to deeper insights with greater ease than ever before.
The talk will focus on Scopus AI, a next-generation tool that blends generative AI technologies with Scopus' trusted content and data.
Sharing a Lakehouse at Nordea Asset Management – how we’re implementing Data Domains with Dremio
The application of GenAI doesn’t have to be Generative!
Whilst we have collectively formed behind the term of GenerativeAI, the maturing application and value in the use of technology is in its non-generative application.  How do we blend the user expectation GenerativeAI is creating with the practical application in an Enterprise and Trustworthy context, and what does this mean for the role of data science, engineering and governance.
Business Driven Data Integration Automation – Save Time and Cost and Deliver Better Results
During the session, we will comprehensively cover the entire data integration process. We will discuss the horizontal flow from data source to destination and the vertical aspects from infrastructure to operations. All of this will be presented in just a few minutes, highlighting how our solution can help you lower costs, mitigate risks, and enhance the maintainability of your data engineering tasks.
With the ever-growing volume of data, increasing number of data sources, and rapid pace of change in data sources, data integration projects have become highly complex. Consequently, this complexity often leads to poor data quality, resulting in flawed business decisions based on unreliable data.
In this session, we will demonstrate how we utilize the business-driven Datavault Builder data warehouse automation solution to effectively reduce the complexity of such projects. Our approach involves replacing up to nine separate tools with a highly automated, cloud-native solution. We emphasize the importance of standardization and collaboration between business and IT stakeholders as the key to success.
How vision care leader leverages real-time analytics to increase production yield
Learn how Alcon, a world leader in eye care, ingests and analyses large-scale and real-time manufacturing data to increase production yield bringing in multi million dollar productivity gains.
' How to visualize and analyze data in real-time.
' How to ingest large-scale manufacturing data in real-time.
Attend this talk to learn more about:
' Ways of leveraging data & analytics to achieve productivity gains.
' Lessons learnt from usage of AWS IoT Greengrass and HighByte Intelligence Hub.
The building blocks of Data Culture during transformation
Through transformational change, especially in the world of data and technology, creating a data culture and supporting the rollout of change is critical to success. We'll talk through how the setup of a data academy to support engagement, community building and training and development can be a catalyst and enabler for cultural change. We'll also talk about how the Data Academy has rolled out data for skills training across multiple customer facing areas and our ambitions to create a data driven, data fluent, data skilled workforce.
Unlocking the Power of a Connected World: Enhancing Business Intelligence through Graph Thinking
In our interconnected world, the broader context plays a crucial role in influencing outcomes. However, current practices in Business Analytics and Decision-making often focus on isolated entities, neglecting their interconnectedness. This presentation delves into the realm of Graph Thinking and its potential to improve decision-making by embracing contextualized data analysis. We explore the identification and modeling of real-world business problems using graph representations and discuss how Graph Analytics and Graph Machine Learning can augment and enhance existing Analytic stacks. By leveraging the power of graphs, organizations can unleash untapped insights, enabling better and faster decision-making in today's complex business landscape. Don't miss it!
How Adaptavist leveraged Sifflet to achieve actionable data quality at scale
Dive into Adaptavist's journey of integrating Sifflet into their data ecosystem and uncover the strategic approaches, challenges overcome, and transformative outcomes that propelled them to the forefront of data-driven innovation.
Careers in Data: Analysts, Engineers, Scientists & their Superpowers
Learn from this panel of Data Scientists, Engineers and Analysts about the distinct skills, contributions and responsibilities of each role, how they collaborate and complement one another and what the unique challenges and obstacles are.
In the fast-growing world of data, there is not only one specific skill set required to be a data professional. If you are looking for a role in data or trying to build out a data team, it can be hard to make sense of it all.
Don’t Panic: The Hitchhikers Guide to AI Governance
Artificial Intelligence and Machine Learning are nothing new to the data community - we have been using ML models for prediction and analytics for years. Recently though, with the rise of the Large Language Model (LLMs) greater emphasis is being put not on the fact that these ever expanding capabilities can tell you everything from how to make the best tacos to where the highest risk is in your client portfolio, but if it should; if it is legal to do so, what data is being used to tell you that, and if it is high quality enough to drive accurate forecasts. This session is a discussion on how you can adopt the correct (and auditable) approach to getting access to governed, high quality, trusted data for your models and how to do so whilst remaining compliant with the rapidly changing face of AI legislation and regulation.
Empowering Data Security at Scale: Experian’s Successful Migration from Legacy Data Systems to Snowflake
Join us to learn about this migration success story, a testimony to Snowflake's reliability and prowess in addressing modern data challenges within a heavily-regulated environment.
In today's data-centric world, the need for robust, secure, and scalable data platforms is paramount. For organisations like Experian, operating within stringent regulatory frameworks, ensuring data security, privacy, and disaster recovery isn't just a preference, but a necessity. In this presentation, Richard Gaunt, Head of Data Engineering & Technology Innovation at Experian, will delve into how these factors shaped the organization's journey of transitioning from legacy data systems to Snowflake.
This transformation has not only led to significant cost savings for Experian but has also seen an impressive uptake of various cross-functional teams all embracing the benefits of cloud technology. Furthermore, the introduction of Snowflake has enabled Experian to harness new opportunities for secure data collaboration, amplifying their core service capabilities as the organisation continues to scale.
How to Build a FUTURE FIT & Sustainable Data team
Will soft skills overtake hard technical skills?
Join Jez Clark, industry leader & CEO of Eden Smith, as he shares his high-level observations of the labour market, with current market data and insights on salary benchmarking & vacancies. He'll also share his predictions of what we can expect for the rest of 2023 and through 2024.
What are the skill requirements of a modern professional?
How can we train & prepare our teams for unpredictable futures?
And, how does ESG regulation and sustainability fit within data?
If you work with People & Data, this session will give you plenty to think about and actionable advice on how to be FUTURE FIT.
Data to outcome journeys in a no-code, ML world: pitfalls, challenges and solutions
Empowering organizations to drive business value from their data with data governance by the business, for the business.
Federated Data Governance is transforming data-driven value by bringing more business stakeholders into the data supply chain. Accelerated by the power of AI, data can now be governed and managed by the very people tasked with finding new revenue streams and opportunities from it. By empowering business users, organizations can break down data silos, generate insights quickly, and increase productivity, to ultimately drive transformative growth.  Join Adon Blackwood, Security & Compliance Technical Specialist, at Microsoft, to learn how you too can benefit from fully governed, federated data that is primed for both productivity and protection.
Product Showcase: Empowering Everyone to Get Involved with Data Quality
In today's fast-paced and interconnected world, data is critical to everyone's work. However, the burden for maintaining data quality often gets passed around like a hot potato, as no single person or team is solely accountable. As the need for reliable and trustworthy data increases, we must change that. But how can we make data quality a collective responsibility, foster a culture of good data, and empower each individual to contribute to data quality?
During this showcase, you'll witness how to:
Prevent downstream issues and improve pipelines
Join this product showcase and see Soda's modern approach to data quality management in action. Soda bridges the gap between data producers and data consumers, ensuring the right people are involved at the right time to leverage the technical know-how and subject matter expertise of every team member.
Implement self-serve data testing with SodaGPT and SodaCL
It's time to enable everyone to deliver trustworthy, high-quality data for business success.
Integrate end-to-end data quality from ingestion to consumption
Your job in 2024: Turning Data into Vectors
Do you remember the time when each domain of Machine Learning had its own feature engineering approaches and model architectures? And then 2017 happened, and ever since across NLP, Vision, RecSys and beyond we standardized around the Transformer models. They also drive the current Generative AI & LLM hype.
But what does this mean for data professionals?
Well, one of the strengths of the Transformer model family is that they can turn pretty much _any data_ into points in high-dimensional space - we call those points vector embeddings. These vectors offer a rich representation of the underlying data structure - they can help you understand your users better, spot fraudulent transactions faster, identify unwanted content at larger scale or relate other pieces of information to each other in completely new ways.
Simply put, the demand for turning data into vectors is exploding across pretty much all industries - let's discuss what this means for your job in data, the roadmap for your company and the overall impact on the industry.
AI and the shake-up of the legal industry
Cultivating a self-service analytics culture at Bumble.
A Data Fabric for Modern Architectures
Join this session to learn how the combination of Qlik and Talend delivers a data fabric for modern data architectures that serve the widest range of use cases and personas. Qlik Talend offers data integration, data quality, application integration and data governance that work with virtually any data source, target, architecture or methodology
Ever pulled at the loose thread of a data fabric only to watch it unravel?
-	Ensure your business users always have the data they need, whenever and wherever they need it"
-	Eliminate the barriers and backlog between business and IT"
-	Enhance your productivity and increase observability to optimize processing and controls costs"
Whether you're modernizing your cloud data infrastructure, building a data warehouse or lake, ensuring regulatory compliance, or developing an internal data marketplace, see how Qlik Talend can help you in each step of your journey.
Generative AI: OVO Energy + DataRobot A CDO’s Must-Know Guide to Unlock Business Value
Why Most Data Projects Fail and How to Avoid It
Unfortunately, the majority of data projects fail. Yet, they fail for the same reasons. Most management and data teams don't know the reasons a project succeeds or fails. It just appears to be random, hard work, or luck. To help understand the reasons teams succeed, we will introduce the who, what, when, where, and how of data projects. By answering these questions, teams will understand what they're trying to accomplish far better.
Who: Data teams all start with people. This needs to be the right people, with the right skills, and at the right ratios. You will need data scientists, data engineers, and operations all working together.
What: Just saying you want AI isn't enough. You need to know what business value will be generated. There should be a clear and attainable path to value creation. You have to clearly state what you are going to do to create value.
When: Unattainable timelines aren't feasible and neither are 'when it's ready' timeframes. Data projects need to deliver value on a sane timeline. This will include delivering in tranches so the team can gain velocity.
Where: Clusters need to be spun up somewhere. Data needs to be stored somewhere. The data needs to come from somewhere. Data teams need to have a clear plan and architecture of where each piece will be done.
How: Data teams need a clear plan that they are executing. This plan needs a singular focus or the work will go in different directions. There need to be clear technical choices and specific technologies chosen.
Agile Project Delivery for Remote Teams: Tips for Efficient Collaboration and Communication
Real Time and Historical NLP-Enriched Market Dashboard with RisingWave and Chat-GPT
Join us for an insightful presentation on leveraging RisingWave's powerful features to write efficient stream-processing jobs for real-time market data enriched with NLP-based indicators from Chat-GPT. Discover how we can reduce costs by minimizing recomputation of outputs as new data streams in and optimizing external API calls through effective filtering and caching techniques. Explore the benefits of using RisingWave to process market data while harnessing Chat-GPT's insights, enabling cost-effective decision-making in real-time market analysis.
Derisking Your Data Analytics Journey
More and more European companies are wrestling with how to move their data analytics to the cloud. Although each company may be a little different, there are common patterns to the hidden risks and rewards to consider along the way. How can you bulletproof your journey to the cloud? And what are the strategic questions smart customers are asking themselves to avoid the pitfalls along the way and achieve the full promise of cloud? Actian's Chief Marketing Officer, Jennifer Jackson talks through best practices and lessons learned across its 50+ year history of helping enterprise customers.
ESG: compliance, reporting and dashboards – tales from a start-up eco business
This 30-minute session will explore how a data dashboard can help with reporting on sustainability compliance, specifically on GHG and Scope 1,2 and 3 emissions. It will highlight the fundamental questions an organisation needs to ask itself when considering technology requirements for data quality and compiling a scope for an ESG dashboard so that the data held can be used for compliance reporting and to ensure better sustainability decision making.
Technical Data Governance – Unlocking the Power of Data Assets
In this session, I will dive deep into the world of data modelling, focusing on lineage, provenance, and auditability of data platforms. We'll explore how businesses can build a robust data infrastructure that enables them to reverse data transactions and provide transparency for better decision-making and data-driven insights.
I believe this topic will be of great interest to the audience, and I'm looking forward to sharing practical insights and best practices that can empower businesses in their data journeys.
Federated Data Governance: Musings from the Mesh Side
As one of the four key principles of Data Mesh, Federated Data Governance is on the rise. Yet how does it differ from the classical data governance efforts? What have we, as a data mesh community, learned over the past years about what works and what doesn't? As one of the early adopters, I had the opportunity to explore uncharted territory, but that also meant facing many challenges and hurdles along the way.  In this talk, I share my experience & lessons learned on how to drive a federated data governance effort, spanning from communicating governance, building credibility and momentum, choosing your first data product, and maintaining success through fostering a data culture. Join me as we talk about Data Mesh Governance!
Let’s Be Real: Why data governance gets you to data utopia
Reaching 'data utopia' - a state of optimal data management and utilisation - is the dream for many organisations who are keen to embrace AI, automate processes and empower their data teams. However, the reality of getting to this utopia starts with establishing the right data foundations. Only from understanding what data they have, where it is and that it's of good quality, can organisations begin to extract valuable insights and make data-driven decisions. In this session, we illustrate how data governance gives organisations the foundations to make data utopia a data reality.
Metadata Mesh – Metadata Automation in the Data Mesh
In heterogeneous data architectures, vast amounts of metadata accumulate: Information about schemas, formats, descriptions, responsibilities, usage, quality, or classifications is produced in a decentralized manner and must be processed and passed on to enable efficient and secure work with data. A major focus here is on the decentralized metadata platform, which integrates and provides metadata across technologies and organizations. Not only distributed data catalogs have to be connected, but also various tools like for data transformation or data quality. The presentation will provide insights into Zalando's current and future data landscape.
Unlocking Maximum ROI: The next generation of the Modern Data Stack
After the Modern Data Stack: Hello Modern Data platforms. Many organizations deployed a 'Modern Data Stack' to leverage their data in the cloud yet they keep on running into DataOps issues, missing design patterns and integration challenges that are slowing down their teams and time to value. The modern data platforms can solve this problem accelerating time to value by 30% and reducing overall cost by 50%. Join this session to learn about the characteristics of the modern data platform and how they can help your team move forward faster with greater savings.
Panel Debate: Real-life lessons of navigating the journey to a better data culture
Building Scalable Data Products to fuel Data Science Outcomes
If you want to explore data, you have to find it first, and one of the challenges facing data scientists today is that they can't always track down the data they need. Learn how organizations are combining the vast access possibilities with Starburst data products along with Red Hat OpenShift Data Science (RHODS) to unlock a fully hybrid cloud ready data science platform. We will present and demonstrate how data scientists and AI developers can simplify their work using Starburst and OpenShift Data Science.
Empowering Transformation: Our Strategic Approach to Nurturing and Scaling AI Innovation at Cirium
The AI sector is on a trajectory of rapid growth, with global spending on AI poised to double within the next three years. Companies are actively harnessing AI's potential to reshape their operations and develop customer-centric products. However, this transformational journey is far from a linear progression'it's a dynamic evolution marked with challenges and breakthroughs.
Join me in exploring Cirium's transformative journey, where AI has been instrumental in reshaping our business. In this presentation, I'll share practical insights gained from navigating the complexities of transformation, focusing on building strategic alignment to unlock the potential of AI to drive impactful change, foster innovation and collaboration, and spur growth.
Julia-fying your data team: Supercharge your Sales Motion with Agent-Based Modelling
Next, envision a dynamic tournament where algorithms outpace athletes, racing to find the optimal upsell strategy through Agent-based modelling. With Julia, not only do you bypass months of sales experiments, but you also immerse yourself in an ecosystem of tools boasting speed, adaptability, and incredible productivity. I'll showcase how easy it is to then share the results with your stakeholders in a compelling way.
Learn about Julia's transformative power, specifically curated for data and decision intelligence teams. We'll kick off by highlighting Julia's unparalleled effectiveness and its capacity to amplify even small data teams, sharing some lessons and examples from our journey.
Concluding, I'll provide some tips for easy starts with Julia. Experience how Julia converges intricate data and business acumen into actionable insights, prepping both data buffs and business leaders for supercharged data science!
CDP Excellence: Navigating Challenges, Embracing Change, and Shaping the Future
Join Artefact and Treasure Data for insights into the customer data platform (CDP) landscape. Understand market dynamics, the challenges of CDP adoption, and key lessons learned. Discover strategic ways to leverage CDPs effectively and move beyond technical hurdles. Learn what we can expect looking into the future, as well as trends and best practices, emphasising expertise and change management. Elevate your CDP strategy for transformative results and actionable takeaways.
DataOps from a Marketer’s Perspective: Winning Buy-In and Maximising Impact
A history of Language models: Explained by generating session submissions for Big Data LDN
We will also discuss some of the challenges and limitations of language models, including the problem of bias, the need for large amounts of training data, and the difficulty of interpreting the output of these models.
By the end of this session, attendees will have a better understanding of the history of language models, the different types of language models that are available today, and the strengths and weaknesses of these models. They will also have a unique perspective on the potential of language models for generating natural language text, as demonstrated by the session submissions generated during the session.
Language models have come a long way since their inception in the 1950s. Today, they are one of the most important tools for natural language processing and machine learning, and they are used in a wide variety of applications, including chatbots, search engines, and language translation.
In this session, we will explore the history of language models, from the early days of rule-based systems to the latest advances in deep learning. We will examine the different types of language models that have been developed over the years, including n-gram models, Hidden Markov Models, and Recurrent Neural Networks.
To showcase the power and versatility of modern language models, we will generate session submissions for Big Data London using a state-of-the-art language model. Attendees will see firsthand how language models can be used to generate text that is coherent, relevant, and engaging.
The Top 10 Data Governance Tasks that AI can do better than Humans
In this session, we will discuss the Data Governance tasks that AI is best equipped to perform, and where humans fit into the picture. We'll investigate how to clean, integrate, and enrich data in a matter of minutes, add explainability to AI-led decisions, roll back data changes, and put processes in place using automated workflows ' amongst others. We'll also provide guidance and advice on the optimum AI-human relationship for your Data Governance practice.
Spatial Data: The Missing Piece in the Modern Data Stack
In the era of Big Data, the "Modern Data Stack" has emerged as a comprehensive framework for managing, analyzing, and leveraging vast amounts of information.
However, to be a truly modern data stack it must go beyond traditional data types and embrace spatial data.  Without spatial data no framework can address the complex challenges faced by both organizations and society today.
This presentation will delve into the critical role of spatial data in the modern data stack, showing that without it, your data infrastructure and therefore your insights fall short.
We will show how spatial data, and its unique ability to provide location-based insights, is not an optional add-on, but critical for addressing many of today's organizational and societal challenges.
From urban planning and environmental management to public health and logistics, spatial data is necessary to understanding patterns, trends, and relationships, enabling more informed decision-making.
Real-world examples of spatial data in action, will demonstrate its transformative potential.  True data transformation requires spatial data.
Join us as we journey through the landscape of spatial data, revealing its indispensable role as part of a truly modern, robust, and effective data stack.   You will leave with a new understanding of how spatial data is critical to meeting your challenges head on.
How to categorize a huge amount of product feedback using OpenAI and avoid burnout
During startup growth or within a large organization, you may be overwhelmed by the sheer volume of textual data that needs to be analyzed for decision-making or product research. Traditionally, the onus of interpreting and categorizing such data has fallen on individuals, which is a daunting task. However, advances in natural language processing, and in particular the development of LLMs and AI, have gradually begun to provide valuable assistance in easing this burden.
In this talk, we'll explore the challenge of handling and making sense of vast amounts of product feedback data, a significant pain point for companies in the digital age. We will work through a comprehensive example utilizing OpenAI's powerful API, showcasing its costs, difficulties, and capabilities to categorize textual feedback at an unprecedented scale.
We'll also delve into the nuances of OpenAI's API, demonstrating real-world prompts and applications. You'll learn about the OpenAI API, best practices for working with it, and how to integrate and leverage it to derive meaningful insights from a sea of textual data.
Auto Trader UK’s Journey to a Practical Data Mesh
To accelerate the adoption of reliable data and reduce time to insights, the data engineering team at AutoTrader operates self-serve data mesh architecture powering analytics for thousands of employees across the company. In fact, as early as 2021, AutoTrader was one of the first UK companies to migrate to data mesh from a centralized data platform. Over two years later, the team has much to show for it, including domain ownership over critical data sets, and robust monitoring and alerting strategy to triage data incidents, reduced time to insight, and a modern data stack, featuring tools like BigQuery, Looker, Fivetran, and Monte Carlo. Edward Kent, Technical Lead at Auto Trader UK, will present on how his team achieved a practical data mesh, reflecting on lessons learned, key obstacles, and what's next on their journey.
From Vision to Reality: M&C Saatchi Performance’s ETL Evolution Powered by Matillion
During this session, we'll delve into our transformative journey of modernizing and future-proofing our tech stack with a key focus on our ETL solution. This session will:
' Look at why we embarked on this journey and our initial objectives.
' Weigh up the pros and cons of building in-house vs. buying a solution.
' Provide a glimpse into our decision-making process that led us to our ideal partner.
' Discuss strategies for building a cohesive team around the ETL solution.
' Highlight how this foundation paves the way for advanced data science and analytics initiatives.
Data Leadership: 5 lessons learnt on how to attract, build and retain the most amazing data team you will ever manage
In this talk Antje will talk about her experience with bad and great leaders. What she learned from that and what the 5 most important takeaways  are to become a great leader. The focus of this talk is on the most important asset for every company: leaders that want to create career changing opportunities for their team, that will help you grow and learn, that set their ego aside and truly want to succeed as a team, that will drive success for the company they work for, but also understand how data and analytics can positively change consumers and customers lives. There will be funny anecdotes and tips and tricks she will share from her 20 years working experience in the data industry.
Whether you are a manager already, you want to become one or you are tired of your shitty boss, this talk is for you!
How complacency is fueling a privacy crisis
People don't care about privacy because they don't understand what it is.  If they did, they'd be furious
Privacy is being eroded by stealth.  This is detrimental to each and everyone of us because privacy matters deeply.  At the same time, it's easy to ignore privacy because it seems difficult, it feels like no one cares and because getting caught for breaking the rules feels unlikely. Just like the climate crisis, privacy is a collective responsibility. We all need to act now because apathy is not an option.  Fostering a culture where privacy matters is the only way to solve our privacy crisis.  The starting point is making everyone understand and care.  People will then be empowered to act.
Key takeaways
"1.	Organisations are treating our personal information like we're in the wild west"
"2.	As a result, our lives aren't as private as they used to be"
"3.	That leaves the complacent counting the costs"
"4.	While the winners are putting the PR into GDPR"
"5.	I'm going to make you understand. I'm going to make you care.  And I'm going to show you what you can do to help."
Responsible AI
-	Goals of Responsible AI"
-	Roles in Responsible AI"
-	First steps to achieve more Responsible AI"
The Race Behind the Race: How McLaren Racing uses Alteryx to pursue efficiency
Watch a McLaren Formula 1 race car tear around the track at Silverstone or Interlagos, and you have to be impressed by what is a masterpiece of mechanical engineering. But there is more to a McLaren F1 car than just power. Those high-performance vehicles are also some of the fastest-moving computers in the world, with 300 onboard sensors generating some 1.5 terabytes of data each race weekend ' all of which needs to be collected, analysed, and acted upon by the team.
In this keynote session, discover how McLaren's relentless focus on leveraging innovation to perform, combined with Alteryx's analytics automation software, drives breakthroughs to harness and find key insights in complex data with tremendous speed.
From the battlefield: Squeezing the most from your fast data infrastructure
In the early stages, building your Fast Data strategy is easy and cheap: its scope is small, and things are moving fast.
Engineers spend more time building pipelines, teams spin up extravagant resources and you find yourself and others diverting routinely diverting their attention from your core business.
In this talk, we'll explore the problems you'll experience from your infrastructure expanding and many clever solutions to mitigate them.
Fireside Chat: Data Science Apps for Space Data
Learn how Oneweb is building data science models and applications for space data. During this fireside chat, listen to a spacecraft data scientist and senior engineer at Oneweb - a communications company that aims to build broadband satellite internet services. Hear what tools they're using to implement data science models and applications, how they're scaling and operationalising their data science and applications use cases with the use of Snowpark and Streamlit and how they're simplifying their data science architecture. Lastly, hear their learnings and pitfalls to avoid for anyone who is on a similar journey of building data science applications for their organisation.
Navigating the Landscape of Data Observability with Andy Petrella
Join Andy Petrella to delve into his new O'Reilly book, 'The Fundamentals of Data Observability.' In this session, you'll not only learn about the motivations behind the book but also explore practical strategies for incorporating data observability into your daily workflows. Aimed at data engineers and professionals alike, the talk will offer insights into the book's core concepts and how they can help you build more reliable data systems in your organization.
First party customer data has the potential to transform customer experience, but most businesses struggle to realize the potential. Why?
Organizations today have the opportunity to use first party customer data to understand who their customers are and where they are in the purchase process: this creates enormous opportunities to use that understanding to better engage with customers and prospects, personalize the service delivery and drive value - both for your customers and your business. Many organizations try to realize these possibilities but struggle, because building a suitable customer 360 data foundation is so difficult.
Join Snowplow to understand the organizational, compliance and technical barriers that make  building a data foundation is so difficult, and how organizations can adopt newer approaches to data governance, including data contracts, to solve these challenges and use data to deliver superior customer experiences and value.
Exploring Generative AI Applications in Commodity Industry Intelligence Services
Looking at first Proof of Concepts and technical innovation opportunities created by Generative AI within the Commodity Industry. We will look at PoC based on the LNG market but also at other ideas and next steps.
Panel Debate: Data-vengers @ Big Data LDN
The Non-Wizard’s Guide to Supercharging Data Pipelines
As data increasingly becomes the lifeblood of businesses and organizations, optimizing data pipelines is becoming more and more crucial for engineering organizations. How does one know where to start?We walk through our journey of pushing the performance boundaries of Airbyte's pipelines to achieve a 4x speed up.We debunk the myth that performance optimization is solely the realm of engineering wizards, concocting magical algorithms and techniques behind closed doors. Instead, we showcase how understanding the system as a whole and employing iterative strategies can incrementally unlock significant performance gains with minimal engineering complexity.We illustrate some hidden pitfalls we stumbled into around pipes and backpressure, and identify some practical lessons and techniques we hope all devs can benefit from.
How to choose the right infrastructure and solutions for your machine learning projects
AI has quickly become a main focus topic for organisations and governments worldwide. What started in small R&D environments in the 'big data' revolution a few years ago has now grown into a mature practice where data scientists and data engineers work together towards common business goals. AI is powering the finance, retail, energy, and healthcare sectors. This growth also comes with challenges; machine learning models cannot live on their own and have to be incorporated into production environment. To that extend programming frameworks, tools and infrastructure are evolving at an enormous pace. New architectures and design pattern have arrived to work with these new technologies. One important field of research is MLOps, which has evolved into a way of working and set of best practices to deploy, test, manage, and monitor machine learning models in production. In this session we'll explore this subject. Bas will present a reference architecture that can be applied to any machine learning project. From there we'll explore the options for use cases and solutions. Based on this information you should be able to create your own solution architecture and reason about the technology options.
The power of decentralisation – a story of making data governance sexy
The power of decentralisation - a story of making data governance sexy (and successfully embedding it across the organisation)
We believe that while compliance with data privacy and security rules and regulations will always be an essential part of data governance, modern data governance should strive to be adding business value way beyond that.
The talk will focus on how the principles of decentralisation and domain ownership popularised by data mesh were applied to designing a modern data governance framework that was subsequently successfully rolled out across one of the biggest and most impactful charities in the UK.
You will hear from Svetlana and Caitlin (Head of Analytics at CRUK) who will share their experiences in redefining data governance as an enablement function and how applying the best practices of the domain-driven design to the data governance framework enabled quick decision making and empowered cross-organisational  teams, creating a ripple effect across the whole organisation drastically shifting the narrative towards maximising the value derived from data.
We will share examples and actionable takeaways about how by creating clear roles and responsibilities for data governance combined with the domain-centric model of ownership, you too can facilitate a closer collaboration and partnership between various teams firmly positioning data as a shared asset within your organisation.
Supercharging data modeling with native cloud features for cost-effectiveness and efficiency
Serge Gershkovich - data architect, industry expert, writer, and thought leader, will discuss how to leverage native cloud features to create efficient designs using time-tested modeling principles. We hope you'll join us to discover the role that data modeling plays in modern cloud data platforms - supporting enterprise teams from engineering, to data science, to governance.
Data Strategy 101: The Essential Guide
Been asked about your Data Strategy and were unsure what it meant and where to start? In this talk Ela will tell you why your company almost certainly needs one, how to assess what's required, what it should include and how to evolve it. The focus of this session will be practical take home that you can implement right away.
Assuring Data Quality At Scale – A study of Data Mesh in Practice
Data Mesh is a Data Architecture pattern that has emerged recently. It advocates for
centralized capabilities for that constitutes data platform and federated governance across all data products which themselves are domain specific.
Data is the lifeblood of any Data-Driven organisation. High-value Data products, AI/ML pipelines and business decisions are made based on data.
Therefore, it is highly imperative that this data is of the highest quality and continues to stay high quality. Consequently, there is a need to do this centrally to provide standardisation and promote transparency and trust on the data quality metrics calculated and used to measure quality.
This talk is about the practical application of Data Mesh principle in the Data Quality space, the challenges of implementing such capability at scale and of course the opportunities it has unlocked within the organisation in turn
How Anheuser-Busch InBev Unlocked Insights on Tap with a Gen AI Assistant
Gaining a competitive edge in today's business landscape requires instant, actionable insights. Hear how global beverage titan Anheuser-Busch InBev is transforming its workflows with AI assistants for automated and ad hoc analysis and insights. We'll discuss real-world use cases and highlight how Insights teams are empowering their business counterparts to make faster, better decisions at scale.
Beyond conversion; using data to build a hobby
Findmypast is a leading family history company, with the largest collection of UK and Irish records in the world. Subscription user journeys are rarely linear, especially in hobby-based products where users must engage heavily across different features to maximise utility. Consequently, traditional funnel-based acquisition-conversion models struggle to provide the necessary insight to optimise marketing channels. Here, we show how FMP encompasses engagement data into channel optimisation, and furthermore, how we create a feedback loop of data to create personalised
product experiences.
How the flow of data is transforming the water industry
Water utilities companies have extremely large and complex networks to manage across wide geographic regions. Effective use of data is the key to unlocking more sustainable and efficient utilities systems in the UK.
Join Tina Diamond and Simon Turner in this fireside chat to discuss how Data, AI, IoT and Analytics is transforming how the Water Sector delivers clean water to the UK population.
Data Anonymization Revisited: A Case Study of the Pensions Data Project
Getting data anonymization right can be tough, given the GDPR's requirements and various interpretations of it. In this talk, we present a case study of how secure data sharing can be achieved, and in what situations data can truly be considered "anonymized".
The Pensions Data Project is a government-backed, industry-wide research initiative to gain insight on people's saving patterns. It also addresses the issue of small-pots pensions that are scattered across different providers. The first step that needed to be addressed was how data sharing and matching of people's pensions across providers could be done in a compliant manner.
Data Modelling in the Age of Connection
Relational data models served us well for a few decades. Then, non-relational
models took the world by storm, altering the way we perform domain data
modelling. But, as it turns out, modelling reality can often be more
challenging than anticipated. We will take a sneak peek into the complex world of the UK's property market, and try to model its idiosyncrasies, ultimately showing the need for more advanced data relationship paradigms, and which database technologies can come in our aid.
Building Cloud-Optional Systems
The physical world is the world of edge technologies, whether it's mobile point of sale systems, IoT sensors or Robots that power factories. These applications generate and demand tremendous volumes of transactional data that need to make it to big data, cloud analytics, and AI systems to transform data into information. However, cloud dependent systems and connectivity remains brittle, costly and a serious barrier for businesses to make resilient flow of data. In this talk we show a marvelous architecture to enable edge apps to sync data to cloud AI and analytics systems even without a direct cloud or internet connection.
Accelerating Data Product Delivery without making a Mesh of it
From Buzzwords to Breakthroughs: Dave and Dan’s guide to creating an effective data strategy
Unlocking the Human Element of Data: A People-Centred Approach to Data Transformation
Are you passionate about data but find it frustrating that others don't see its value?
Do you find it challenging that although data is valuable to you and your organisation, those around you don't seem to care?
Do you have a data strategy, or are you in the process of developing one with all the necessary messages, but still lack traction from the business?
Join Liz Henderson and Bandhu Das to learn from their experience in driving large-scale data transformation at complex organisations.
Liz Henderson is Capgemini's Executive Advisor and one of the UK's most respected data leaders. She has a track record of driving significant value from data with both Fortune 500 and FTSE 100 organisations. Before joining Capgemini, Liz was a former Chief Data and Analytics Officer.
Bandhu Das is leading Defra's data transformation to maximise the use of more than 10k diverse datasets, ranging from satellite imaging and IoT sensors to citizen science and paper records, with greater efficiency and trust. This involves establishing data management principles, processes, and governance that work across federated domains. Before joining Defra, Bandhu developed and executed the HM Treasury's '1tn Public Spending Data strategy.
In this insightful talk, Liz and Bandhu will reveal the secrets from both the public and private sector of getting more people within your organisation to value data. They will share their extensive experience in data transformation and explain why some people may not care about data as much as you do.
Through their engaging discussion, you'll gain a better understanding of how to change the mindset of those who don't see the value of data. You'll learn how to leverage data to its fullest potential in your organisation, and take your data strategy to the next level.
If you want to transform your organisation's approach to data at scale, this talk is a must-attend event.
Data Culture & Data Fluency: The Holy Grail
Data Culture and Data Literacy are essential to the success of any Data Strategy. However they are some of the most difficult items to achieve. In order to achieve these goals we need to think outside the box and be creative. Learn how Chaucer have used marketing strategies and creative experiences to draw business users in and engage their curiosity.
Unlocking the power of Generative AI: Modern Data Quality
Sure, we've all heard about Generative AI, and we understand the 'Garbage In - Garbage Out' principle that underpins it. But what if we told you that Generative AI can be the key to solving data quality challenges?
Join us in this captivating session with Raj Joseph, Founder and CEO of DQLabs, as he takes you on an exhilarating journey beyond the ordinary. Discover how Large Language Models (LLMs) can revolutionize your approach to data quality.
Intrigued? Get ready to delve into the world of possibilities as Raj showcases real-world, mind-blowing applications of LLMs through an electrifying live DQLabs demo.
Data ethics – why we need to go beyond the law
While the rise of generative AI has opened up a lot of new opportunities for businesses to automate workflows, it has also raised a lot of questions about how and what data is shared as well as threats to our privacy. There are concerns that inaccuracies in the datasets that generative models use could amplify misinformation, bias and other unsavoury outcomes, perhaps most importantly you may well feel you are no longer really in control of how data is now used in your organisation as LLMs have put this in the hands of every employee. As technology is moving faster than legislation, who do we turn to safeguard society from the worst potential excesses of AI?
The answer may lie with your business. We need to take data ethics into our own hands to make sure that data is used for good. This goes beyond protecting sensitive business information or employees' personal details, it is also the lifecycle of data, creating ethical algorithms and automations, algorithmic transparency and building diverse data teams. Security and compliance training is prioritised every year by organisations, so why shouldn't we do the same with data ethics?
In this interactive session, Natalie Cramp, CEO at data consultancy Profusion, will explore Profusion's recent data ethics research findings - which found that 83% of business leaders feel 'morally uncomfortable' about how their company uses data - and share top tips from The Good Data Guide.
Building next-gen applications on a unified data platform
Cutting edge Data and AI applications are fundamental to achieving business success. Hence, the architecture underpinning your data applications is paramount. Winners will be those who can effectively and optimally unify data pipelines with AI & ml capabilities to build next-gen applications.
Let's decode how data teams can collaborate and manage rapidly changing business requirements using a cloud-agnostic, low code, extensible data platform.
In the session you will learn how to:
-	Seamlessly connect, acquire, and integrate data from diverse sources, ensuring a unified data foundation for your applications"
-	Infuse AI and machine learning into your data processing applications"
-	Create blueprints for solving business problems and establish developer culture"
-	Empower IT to move with the agility required to cater to ever-changing business needs"
-	Capture changes in real-time from online operational data stores and sync with analytical stores"
Jaguar TCS Racing uses high-speed data analytics to squeeze out every ounce of performance.
Join this session to find out what Big Data - both structured and unstructured - means to the Jaguar TCS Racing Formula E team. Jack Lambert, Research and Innovation Manager of JLR Motorsport, will be taking your questions live as he gives you an overview of Formula E and Jaguar TCS Racing, taking a look at the Gen3 Jaguar I-TYPE 6 race car (the most advanced all-electric Jaguar race car ever with a top speed of 200mph/320kph). After this, we will take a deeper dive into the technology used behind the wheel - describing why milliseconds matter in the race to perfection.
Modern DataOps in the Azure Cloud
Modern data platforms deserve the love and attention that web applications get when it comes to modern DevOps approaches. Data platforms often lack the same rigor and formalization of DevOps processes, such as little to non-existent test coverage, inconsistent and sporadic development and collaboration techniques, and a less efficient or formalized feedback loop when addressing end-user issues or ensuring quality throughout all areas of the solution. And with the transition to the cloud, new practices are necessarily having to be adopted to keep delivering high-quality solutions. Applying these practices to modern data platforms is sometimes a struggle, so this session aims to demonstrate tried and tested tools and strategies which will set you up for success with your next Azure cloud data project.
Work with AI to See, Understand and Act on Data
Tableau, backed by Salesforce, has been at the forefront of empowering the full spectrum of data users to revolutionise their interactions with data through AI. This session will explore how:
-	Tableau Pulse brings data to more consumers by infusing trusted, tailored metrics into their flow of work."
-	Salesforce Einstein enables you to leverage generative AI while maintaining trust by overcoming challenges around data leakage and hallucinations."
-	Salesforce Data Cloud enables dynamic grounding by building a connected view of your business and customers."
Real time decisions with data
Matchmaking is matching demand, with the right supply to facilitate a good transaction, ei a person wanting a taxi with one going in that direction, or the right team in a game.
With some worked examples, we'll walk through ingesting data, capturing user intent, and building real time analytics pipelines with Apache Kafka & Apache Flink and Opensearch. Then we'll see how we can blend that with transactional data to drive user actions while handling real world problems such as flaky users, sudden traffic jams, or losing WiFi, .
One of few universal truths is that people prefer not to wait. Whether they're looking for a game to play, the next episode to watch, a taxi home, or even a date, there is a finite amount of time you can delay a user for before they will leave your service. However if the match is not good enough, that can actually be worse.
You don't want to match someone in London with a taxi in Tokyo, or a new player against a world champion. Also, history can be important - trying to book a taxi to travel outside its normal working area will not be popular.
Good matches rely on many factors, some being hard constraints, and others which are weighted scores. Some of these can vary in real time. You don't match someone in London with a taxi driver in Tokyo or a new player against the world champion. In addition, you'll want to know what a user has done in the past so you can inform that match with past behaviors like balancing a team for a game, or matching people based on likely first date locations.
So let's explore streaming joins, Batch pre-aggregation, and dealing with rage quits in an open source architecture designed to scale out across the globe
Careers Opportunities in DATA at RELX
Unlocking value through federated data products
Join Andrew Mott, Partner Solution Architect at Starburst, for an exploration of Data Products. In this session, we'll discuss how Data Products have gone beyond the data mesh philosophy.
We'll underscore the importance of proactive data management, focusing on the need to anticipate and meet data requirements to establish a robust data supply chain. You'll gain insights into the various types of Data Products and their alignment with specific data consumer demands and business objectives.
Our conversation will revolve around bridging the operational-analytical gap, showcasing how self-service data access is critical to drive organisational value. Moreover, we'll explore the role of data modeling in enhancing data usability and accessibility.
Andy will also be giving away free copies of his book, Data Products for Dummies, to the first 50 attendees of this session.
In an increasingly uncertain business world, why building data capability is your best route to innovation?
Data is the global currency of business and innovation. Add talented people, AI and unlimited cloud computing to the mix and we can transform industries, product-by-product and service-by-service.
The scarce resource is talented people, with half of all UK businesses struggling to reach their potential, due to a lack of technical data talent and the fact that a handful of tech enterprises has a near monopoly on talent acquisition. David Pool, QA's Portfolio Director for Data & AI, will explain how organisations can overcome this skills-drought to build world-class data science and AI teams, capable of preparing any organisation for a digital and data-first future.
Big Data processing technologies and approaches across the RELX organisation
Data Governance & Data Quality, how to make them work for each other
Whether you start with Data Governance or Data Quality, it is vital that you start. BUT starting with only one leads you down the path of failure as you tend to short-change other Data Management capabilities. But even more importantly, being able to have one capability support another allows you to broaden your reach, win more friends and influence more stakeholders. And of course, to show success!!
Sue will give you some insight into how to make these two crucial Data Management capabilities work together:
-	Understanding these capabilities"
-	Balance your strategy"
-	What to do right"
-	What not to do"
-	How to measure what you are doing"
-	Some tips on getting buy-in"
Transformative AI: Beyond the “Genai” Phenomenon
Panel debate: ESG & Data Analytics
What’s in it for me? How organisational psychology can transform your data literacy programme
Maybe you've already introduced your data literacy programme and are struggling with engagement, or maybe you're just setting out and want to maximise your chances of success. In this talk, you'll discover how you can motivate people to successfully change and ultimately answer that all important question for learners: What's in it for me?
It's hard to believe that when organisations are going through change, like learning new data skills, they can overlook the key component that underlies everything in business ' humans. While we are adaptable, there's also an inherent rigidity to us: our primal brains aim to keep us safe. We naturally seek stability, predictability and routine. When we're confronted with the need to think, feel and act differently, we resist. People do want to do the right thing, they just need help getting there.
Generative AI in Data Management and Analytics – A New Era of Assistance, Productivity and Automation
The emergence of generative AI has been described as a major breakthrough in technology. It has reduced the time to create new content, it can generate new code and has triggered a new wave of innovation that is impacting almost every type of software. New tools, applications and functionality have already emerged that are dramatically improving productivity, simplifying user experiences and paving the way for new ways of working. In this keynote session, Mike Ferguson, Conference Chair of Big Data LDN and Europe's leading IT industry analyst on Data Management and Analytics, looks at the impact that generative AI is having on Data Management and Analytics and at what it can do to help companies shorten time to value and govern data in a data-driven enterprise.
Maximizing Data Investments with Automated GenAI Insights
Training models on ALL your data, structured and unstructured, at exabyte scale.
Pipelines and platforms built in the age of Big Data, which focused on structured and semi-structured data sources, are ill equipped to train on large scale, unstructured data collected from the natural world. Organizations are struggling to keep up, and often resort to building bespoke environments which are challenging to maintain and operationalize. VAST provides easy to manage solutions which unify structured and unstructured data processing, curation, and storage to enable Gen AI and other next generation workflows to efficiently operate at scale.
Modern Data Stack at EG
Seeing is believing. Creating role models is one of the most powerful weapons that we have in our Arsenal for Change.
You have to see it to be it' has become one of the most important mantras we hear, as we look to improve all areas of diversity and inclusion. From Women in Data''s research we know that role models are more important for women than men, 64% of women - that is 2 thirds of women - working in tech say that they have been inspired by a role model compared to 47% of men.
So how do we find and elevate these role models? Hear from Di Black and Robin Sutara, Twenty in Data and Tech titans as they talk about their experience of seeing and being role models and what it means in their career.
Simplifying Real-Time ML Pipelines with Quix Streams: An Open Source Python Library for ML Engineers
As data volume and velocity continue to increase, the need for real-time machine learning (ML) is becoming more pressing. However, building real-time ML pipelines can be complex and time-consuming, requiring expertise in both ML and streaming application development. This talk will address this problem by introducing Quix Streams, an open-source Python library that makes it easy for data scientists and ML engineers to build real-time ML pipelines without having to learn the intricacies of building a streaming application from scratch.
In this talk, we'll cover:
- The growing importance of real-time ML in today's application stack, and the use cases for real-time ML processing.
- A comparison of different ML architectures (batch, request-response, stream, and hybrid) and their pros and cons
- The current state of streaming architecture, which is typically Java-based, and the challenges this poses for data scientists and ML engineers who primarily work in Python
- An overview of Quix Streams and its features, including a demo of how to use it to build real-time ML pipelines
This talk is relevant for data scientists, ML engineers, and software engineers who are looking to adopt new technologies and practices in order to build real-time ML pipelines and stay current in their field.
Big Data LDN 2023 Headline Keynote: Tim Peake